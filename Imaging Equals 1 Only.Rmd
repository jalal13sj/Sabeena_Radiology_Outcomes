---
title: "247_data_analysis_for_Sabeena"
author: "Marshall"
date: '2019-05-02'
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,          # don't show code
  warning = FALSE,       # don't show warnings
  message = FALSE,       # don't show messages (less serious warnings)
  cache = FALSE,         # set to TRUE to save results from last compilation
  fig.align = "center",   # center figures
  fig.asp = 1,          # fig.aspect ratio
  fig.width = 5       # fig width
)

```

# Summary
I don't think there is evidence of confounding from the measured covariates. 

**Overall, there is at most a small effect on MD time due to the intervention. **

Some of the analyses don't support that there is a difference between the MD time pre and post intervention. There might be a stronger effect of the intervention in some subgroups, but the subgroup analysis also shows the intervention increasing MD time in some subgroups, which is odd. There may be unmeasured confounding that is distorting the relationships. Below there is a summary and then each chunk of code has a short explanation. 

## Data
group:	The intervention, Pre 24/7 support, Post 24/7 support;	1 = pre, 0 = post
mdex:	The outcome, Md time (min)	
ctas:	Canadian triage and acuity score;	1= dead/ resuscitate, 5= almost normal
Imaging:	Was imaging done;	0= no imaging, 1= imaging done
todseen:	Time of ay when seen by doc;	1= morning, 2= evening, 3= night
trauma:	Was it a trauma patient;	0= non trauma patient, 1= Trauma pt
adm:	Patient admission to the hospital;	0 = not admitted, 1= admitted

I filtered out the imaging = 0 data. I'm assuming that patients not requiring imaging could not be affected by the intervention (24/7 imaging support). 

Missing data: Very little missing data so I'm assuming that it is MCAR. 

Measurement error: Out of 81,099 observations, there were 15 instances where the outcome was recorded as "0" minutes. If there were a lot more "0" entries, I'd be more worried about those entries and measurement error in general. 

##Confounding
Potential confounders were measured, however when looking at their distribution between the groups, they look pretty even. In other words, they don't have much of a relationship with the exposure/intervention, which means they don't meet the criteria for confounding. I do some subgroup analysis throughout and I do throw the potential confounders into some of the regressions just out of curiousity, but fundamentally I don't think they are confounding the relationship between the intervention and outcome. 

Possible unmeasured confounders:
-change in personnel 
-change in perfromance of personnel
-change in complexity of cases
-changes in mdex recording
-change in operating procedure other than the intervention

##Statistical Test
We can do a Mann-Whitney U test (we don't have censoring and this test does not assume a normal distribution). This test gives a p = 0.078. We don't have enough evidence to reject the null that data from the two groups come from different populations (ie: the intervention did not have an effect). This is probably the simplest, most straight forward and easily defendable analysis. I saw one of the references that was sent to "Clinical impact of extending after-hours radiology coverage for emergency department computed tomography imaging" (Samer Dabbo, Catherine Varner, Robert Bleakney, and Howard Ovens; 2014) used a Mann-Whitney U test on what appears to be similar data. 

Note: The post intervention median outcome (Md time, mdex) was *lower* than the pre intervention median. The post intervention mean outcome was *higher* than the pre intervention mean. 


##Models
The p value from the Mann-Whitney U test is limited in describing what's going on, so I tried some models out. I had a tough time fitting the data to a model. I think Kaplan-Meier survival analysis is probably the safest of apporaches I take below because it doesn't require an assumption of an underlying model. The other models are included as an exploration.

The outcome is "time-to-event", which is time to completion of the process (ie: time with the doctor). This lead me to survival analsyses. Cox doesn't seem to work because it doesn't look that the hazards are proportional (hazard = instantaneous potential that the process is complete, ie: the end of mdex time). I thought about investigating hazard proportions that vary with time for the Cox model, but in the clog log plot the lines cross multiple times and I think that means it would have to be a polynimial, so that's probably not worth it. Weibell isn't appropriate either, the hazards are not constant. I look at the data using Kaplan-Meier (KM) because that method doesn't require an underlying model. I also did some exploratory KM analyses in subgroups. The unfortunate thing with KM is that it can't really tell us the magnitude of the effect. 

I also did some plain old linear regressions, but when you look at the residuals, you can see that they are not normally distributed (long right tail). If we want to stick with a linear regression, we could make the argument that the residual plot is not horrible, that linear regression is robust in general, and that we are only looking at a two-level categorical determinant (ie: perfectly linear). I think that argument holds a bit of water, but I think the KM does just as good of a job telling us there is a different due to the intervention. The linear regression might give a false sense of precision. We have a large number of observations so our random error and CIs are quite small, but there might be unmeasured confounding, measurement error, and bias affecting our results which means we are not as precise as the narrow CI would make us feel. 

To address the residuals, I also did a log-linear regresion where I log-transformed the outcome and then performed the linear regression. That corrected the issue with the residuals and they came out normally distributed.

I also did an ordinal logistic regression. 

##Effect of group: 
The Mann-Whitney U test says that there is no effect due to group. Looking at the KM and other analyses, at most, the effect of group seems to be very small. It seem that the post intervention group usually has a smaller median mdex, but that the pre intervention gets "faster" after hitting the median (ie: it is quicker for "longer" cases). As an analogy, the post intervention group is like a sprinter that is quick and has the fastest 100 meter time and the pre intervention group is slower out of the blocks, but wins the 400 meter race with a strong back half of the race. The post intervention group is faster for mdex times under about ~400 minutes, and then it becomes slower.

Sub-group analysis: Intervention may decrease the mdex (mean and median) time for trauma patients and patients that are not admitted. The intervention may increase mdex time in admitted patients. There may be subgroup effects in CTAS and Todseen, but it's hard to say. These subgroup results are consistent across most methods. 


```{r}
setwd("/Users/macbook/Documents/McGill School/Sabeena_Radiology_Outcomes")

#this data has the blank rows and "all-but-id" blank rows removed. It also has extrat binary colmns for the categorical variables for use in winbugs
wb_data <- read.csv("247_data_no_NA_GOOD.csv")
wb_data_na <- read.csv("247_data_some_NA_GOOD.csv")

wb_data$X <- NULL
wb_data_na$X <- NULL

#set factors to factors
wb_data$ctas1 <- as.factor(wb_data$ctas1)
wb_data$ctas2 <- as.factor(wb_data$ctas2)
wb_data$ctas3 <- as.factor(wb_data$ctas3)
wb_data$ctas4 <- as.factor(wb_data$ctas4)
wb_data$ctas5 <- as.factor(wb_data$ctas5)
wb_data$ctas <- as.factor(wb_data$ctas)
wb_data$todseen <- as.factor(wb_data$todseen)
wb_data$todseen1 <- as.factor(wb_data$todseen1)
wb_data$todseen2 <- as.factor(wb_data$todseen2)
wb_data$todseen3 <- as.factor(wb_data$todseen3)
wb_data$group <- as.factor(wb_data$group)
wb_data$imaging <- as.factor(wb_data$imaging)
wb_data$trauma <- as.factor(wb_data$trauma)
wb_data$adm <- as.factor(wb_data$adm)

#repeat with na
wb_data_na$ctas1 <- as.factor(wb_data_na$ctas1)
wb_data_na$ctas2 <- as.factor(wb_data_na$ctas2)
wb_data_na$ctas3 <- as.factor(wb_data_na$ctas3)
wb_data_na$ctas4 <- as.factor(wb_data_na$ctas4)
wb_data_na$ctas5 <- as.factor(wb_data_na$ctas5)
wb_data_na$ctas <- as.factor(wb_data_na$ctas)
wb_data_na$todseen <- as.factor(wb_data_na$todseen)
wb_data_na$todseen1 <- as.factor(wb_data_na$todseen1)
wb_data_na$todseen2 <- as.factor(wb_data_na$todseen2)
wb_data_na$todseen3 <- as.factor(wb_data_na$todseen3)
wb_data_na$group <- as.factor(wb_data_na$group)
wb_data_na$imaging <- as.factor(wb_data_na$imaging)
wb_data_na$trauma <- as.factor(wb_data_na$trauma)
wb_data_na$adm <- as.factor(wb_data_na$adm)

#this is where I can set the whole dang thing to with or without imaging
wb_data <- subset(wb_data, imaging == 1)
wb_data_na <- subset(wb_data_na, imaging == 1)
#nrow(wb_data_i1)
nrow(wb_data)
sum(wb_data$mdex == 0)
sum(wb_data$mdex < 5)
library(ggplot2)

```

##Distribution of turn around time (mdex)

The first plot is all the data and the following two plots are zoomed in on the smaller values (notice the x axis)
```{r}

ggplot(data = wb_data_na, aes(x = mdex, color = group)) + 
  geom_histogram(binwidth = 200, alpha = 0.2, position = "identity", fill = "white") +
  labs(title = "Turn Around Time Distribution by Group", color = "Group", x = "Turn Around Time (minutes)", y = "Count") +
  scale_color_discrete(name = "Group", labels = c("post-24/7","pre-24/7"))
#looks like poisson, looks like group 1 and 2 have extreme observations

#look at the 0-1000 mdex range
ggplot(data = wb_data_na, aes(x = mdex, color = group)) + 
  geom_histogram(binwidth = 50, alpha = 0.2, position = "identity", fill = "white") + xlim(0, 1000) +
  labs(title = "Turn Around Time Distribution by Group", subtitle = "TAT < 1000 mins", color = "Group", x = "Turn Around Time (minutes)", y = "Count") +
  scale_color_discrete(name = "Group", labels = c("post-24/7","pre-24/7"))

ggplot(data = wb_data_na, aes(x = mdex, color = group)) + 
  geom_histogram(binwidth = 5, alpha = 0.2, position = "identity", fill = "white") + xlim(0, 100) +
  labs(title = "Turn Around Time Distribution by Group", subtitle = "TAT < 100 mins", color = "Group", x = "Turn Around Time (minutes)", y = "Count") +
  scale_color_discrete(name = "Group", labels = c("post-24/7","pre-24/7"))


#the 95th quantil is this
#quantile(wb_data_na$mdex, 0.95, na.rm = T)
#mean(wb_data_na$mdex, na.rm = T)
#sd(wb_data_na$mdex, na.rm = T)
#mean is smaller than the sd...check for overdispersion later


```

There are more very low values in the post 24/7 group than in the pre group. There are more moderately low values in the pre group than in the post group. If there is no confounding, then this suggests that the effect of the intervention switches. 



Now let's take a look at the TAT (mdex) in each group. The first plot is with all of the data and the second has trimmed out outliers so we can get a better view. 
```{r}

ggplot(data = wb_data_na, aes(x = group, y = mdex)) + geom_boxplot() +
  labs(title = "Turn Around Time by Group", x = "Group", y = "Turn Around Time (minutes)") +
  scale_x_discrete(labels = c("post 24/7", "pre 24/7"))

ggplot(data = wb_data_na, aes(x = group, y = mdex)) + geom_boxplot(outlier.shape = NA) +
  scale_y_continuous(limits = c(0, 600)) +
  labs(title = "Turn Around Time by Group", subtitle = "Outliers Removed", x = "Group", y = "Turn Around Time (minutes)") +
  scale_x_discrete(labels = c("post 24/7", "pre 24/7"))

```
It doesn't look like a huge difference between the groups, but pre looks a little higher.  


##Table 1 Descriptives and Potential Confounding

Let's look into potential confounders. See which variables appear to have a relationship with the intervention (group) and with the outcome (turn around time, labelled "mdex"). The third criteria for confounding is whether it is on the causal path. 

Take a quick look at "Table 1" stratified by group to see if there are any imbalances of variables between the groups. An imbalance between groups would suggest a relationship with the group. 
```{r}
#install.packages("table1")
library(table1)


#manipulate data set for Table 1, wont do it now, but if the table should be nicer, then we can label all the categories
table1_data_na <- wb_data_na
table1_data_na$group <- factor(table1_data_na$group, levels = c(0,1), labels = c("post 24/7", "pre 24/7"))
table1_data_na$trauma <- factor(table1_data_na$trauma, levels = c(0,1), labels = c("Non-Trauma Pt", "Trauma Pt"))
table1_data_na$todseen <- factor(table1_data_na$todseen, levels = c(1,2,3), labels = c("Morning", "Evening", "Night"))
table1_data_na$adm <- factor(table1_data_na$adm, levels = c(0,1), labels = c("Not Admitted", "Admitted"))
table1_data_na$ctas <- factor(table1_data_na$ctas, levels = c(1,2,3,4,5), labels = c("Dead/Resus", 2, 3, 4, "Almost Normal"))

table1(~ ctas + adm + todseen + trauma + mdex | group, data = table1_data_na)


```
Everything looks pretty balanced. A couple of spots that have a difference of 1.6% between the groups, but most are less than 1%. If someone told me this was an RCT and showed me this as a Table 1, I would believe that randomization worked. This is not an RCT, but it does not look like there is a relationship between group and any of the measured potential confounding variables. Also note that there is very little missing data. 

Side note: we can see the median and mean for each group. The post group has a higher mean but a lower median. 


Can sub-stratify by trauma and ctas if we want. I do that because those might be the least balanced of all the variables (I do proportion tests further down).
```{r}
table1(~ ctas  + adm + todseen + mdex | trauma*group, data = table1_data_na)

table1(~ trauma  + adm + todseen + mdex | ctas*group, data = table1_data_na)

table1(~ trauma  + ctas + todseen + mdex | adm*group, data = table1_data_na)

table1(~ trauma  + ctas + adm + mdex | todseen*group, data = table1_data_na)
```
Some spots have a delta of 3% between subgroups, but still looking very balanced. I think none of the potential confounders have much of a relationship with group. We can also see that the TAT (mdex) aren't hugely different between the groups either. We will come back to this later. 


If we REALLY want to look hard, we can look at each level of each variable and see the propotion that is in each group. Perfect balance (and no relationship with group) would be 0.5, so we can do a bunch of tests of propotion vs the null of 0.5. I'm not sure this adds a lot of value since the n is so large, the CIs are very tight and some of them end up not covering the null even though the proportion is something like 0.51.
```{r}
#check columns proportions, not just overall
c.table <- table(table1_data_na$group, table1_data_na$ctas)
round(prop.table(c.table, 2), 3)
pt.ctas1 <- prop.test(c.table[2,1], sum(c.table[1:2,1]), p = 0.5)
pt.ctas2 <-  prop.test(c.table[2,2], sum(c.table[1:2,2]), p = 0.5)
pt.ctas3 <-  prop.test(c.table[2,3], sum(c.table[1:2,3]), p = 0.5)
pt.ctas4 <-  prop.test(c.table[2,4], sum(c.table[1:2,4]), p = 0.5)
pt.ctas5 <-  prop.test(c.table[2,5], sum(c.table[1:2,5]), p = 0.5)


to.table <- table(table1_data_na$group, table1_data_na$todseen)
round(prop.table(to.table, 2), 3)
pt.to1 <- prop.test(to.table[2,1], sum(to.table[1:2,1]), p = 0.5)
pt.tos2 <-  prop.test(to.table[2,2], sum(to.table[1:2,2]), p = 0.5)
pt.to3 <-  prop.test(to.table[2,3], sum(to.table[1:2,3]), p = 0.5)

a.table <- table(table1_data_na$group, table1_data_na$adm)
round(prop.table(a.table, 2), 3)
pt.a0 <- prop.test(a.table[2,1], sum(a.table[1:2,1]), p = 0.5)
pt.a1 <- prop.test(a.table[2,2], sum(a.table[1:2,2]), p = 0.5)

tr.table <- table(table1_data_na$group, table1_data_na$trauma)
round(prop.table(tr.table, 2), 3)
pt.tr0 <- prop.test(tr.table[2,1], sum(tr.table[1:2,1]), p = 0.5)
pt.tr1 <- prop.test(tr.table[2,2], sum(tr.table[1:2,2]), p = 0.5)
```


Now look at the CIs of the prop tests. These are the proportion of a certain level of a variable that is in group 1 (ie: the pre 24/7 group). This is showing the min and max values of the proportion in group 1 (for each level of variable) that are compatible with our data. 

```{r}
ctas.pt.cis <- data.frame(row.names = colnames(wb_data[c(9:13)]), round(matrix(data = c(pt.ctas1$conf.int, pt.ctas2$conf.int, pt.ctas3$conf.int, pt.ctas4$conf.int, pt.ctas5$conf.int), nrow = 5, ncol = 2, byrow = TRUE), 3))
colnames(ctas.pt.cis) <- c("2.5%", "97.5%")


to.pt.cis <- data.frame(row.names = colnames(wb_data[c(14:16)]), round(matrix(data = c(pt.to1$conf.int, pt.tos2$conf.int, pt.to3$conf.int), nrow = 3, ncol = 2, byrow =TRUE), 3))
colnames(to.pt.cis) <- c("2.5%", "97.5%")


a.pt.cis <- data.frame(row.names = c("adm0", "adm1"), round(matrix(data = c(pt.a0$conf.int, pt.a1$conf.int), nrow = 2, ncol = 2, byrow =TRUE), 3))
colnames(a.pt.cis) <- c("2.5%", "97.5%")


tr.pt.cis <- data.frame(row.names = c("trauma0", "trauma1"), round(matrix(data = c(pt.tr0$conf.int, pt.tr1$conf.int), nrow = 2, ncol = 2, byrow =TRUE), 3))
colnames(tr.pt.cis) <- c("2.5%", "97.5%")


rbind(ctas.pt.cis, to.pt.cis, tr.pt.cis, a.pt.cis)
```
Most of the CIs cover the null of 0.5 and many are very close. Only two CIs extend beyond 2% from 0.5. I'd say that adm probably has the strongest case for being imbalanced, but you could also say trauma and ctas should be considered. I'm still not convinced that they are confounding, but you could make the case for it. Also, keep in mind that at this point we are running a lot of tests, our error rate will be 1/20. 


Just to check the other criteria for confounding, we look at the relationship between the variables and outcome. 
```{r}
boxplot(wb_data$mdex ~ wb_data$trauma, xlab = "trauma", ylab = "mdex")
boxplot(wb_data$mdex ~ wb_data$adm, xlab = "adm", ylab = "mdex")
boxplot(wb_data$mdex ~ wb_data$todseen, xlab = "toseen", ylab = "mdex")
boxplot(wb_data$mdex ~ wb_data$ctas, xlab = "ctas", ylab = "mdex")
```

That's a bit hard to see with the outliers, so take them out:
```{r}
boxplot(wb_data$mdex ~ wb_data$trauma, xlab = "trauma", ylab = "mdex", outline = F)
boxplot(wb_data$mdex ~ wb_data$adm, xlab = "adm", ylab = "mdex", outline = F)
boxplot(wb_data$mdex ~ wb_data$todseen, xlab = "toseen", ylab = "mdex", outline = F)
boxplot(wb_data$mdex ~ wb_data$ctas, xlab = "ctas", ylab = "mdex", outline = F)

```

They all seem to have some sort of relationship with the outcome. Adm, CTAS, and trauma have the strongest relationships.

The third criteria for confounding is "not being on the causal path". I feel confident that none are. So it's really the lack of a relationship between potential confounders and the exposure/intervention that makes me believe they are not confounding the relationship between intervention and outcome.

Group is pre vs post 24/7 imaging support implementation, is there some reason to think that there is a relationship between group and any of the potential confounders that were measured? Eg: once the 24/7 was implemented, more serious cases were sent to that hospital? Maybe there are some secular trends or unmeasured confounders that would have a relationship with these variables and group. Maybe implementation of this intervention coincided with the opening of a skatepark and a resurgence of parkour resulting in a lot more serious injuries. There's no clear reason why there would be a relationship between these potential confounders and group, but it's possible. 

I'm not great at making DAGs in R (yet...), but here are a couple. GRP is the intervention and MDEX is the outcome. C is any of the potential confounders that were measured (eg: adm) and U, U1, and U2 are unmeasured confounders (eg: increasing parkour popularity in the area). 

This would be a DAG that justifies adjusting:
```{r}
library(dagitty)
library(ggdag)
dag1 <- dagitty("dag {
                 U -> GRP -> MDEX
                 U -> C -> MDEX
                 }")

ggdag(dag1)
```

This would be a DAG that does not justify adjusting:
```{r}
dag2 <- dagitty("dag {
                 U1 -> GRP -> MDEX
                 U1 -> C -> MDEX
                  U2 -> C
                  U2 -> MDEX
                 }")

ggdag(dag2)
```
This second DAG could result in bias amplification. Since the relationship we can see between potential measured confounders and the intervention is at most weak, then I don't think the benefit fom adjusting warrants the risk of creating backdoor paths and potential bias amplification. I'm open to discussing. 

Before we look at regressions, lets see if some of the determinants are correlated with each other. There are some statistical tests we can do for this. I need to read up on that and do them. That is a lower priority for now. 

```{r}
table1(~ ctas | trauma, data = table1_data_na)
table1(~ trauma | ctas, data = table1_data_na)
```
Would you look at that! Actually pretty balanced (look at overall distribution and see how each one compares). That means it's hard to predict trauma level based on ctas level. That means less correlated. Or does it? I'm confused. 

```{r}
table1(~ ctas | adm, data = table1_data_na)
table1(~ adm | ctas, data = table1_data_na)

```
Less balanced. That means we can semi-predict whether they were admited based on CTAS. I think this means that if we look at Adm or CTAS, we are semi-gretting the same information. 

```{r}
table1(~ trauma | adm, data = table1_data_na)
table1(~ adm | trauma, data = table1_data_na)
```
So-so. 

##Mann-Whitney U test

There is no censoring and I don't think that there is confounding, so would could simply do a Mann-Witney U test between group = 0 (post) and group = 1 (pre).

Two data samples are independent if they come from distinct populations and the samples do not affect each other. Using the Mann-Whitney U test (aka Mann-Whitney-Wilcoxon Test), we can decide whether the population distributions are identical without assuming them to follow the normal distribution.

The null hypothesis is that they are identical and the alternative is that they are different.
```{r}
wilcox.test(wb_data$mdex~ wb_data$group)

```
This gives a p value of 0.078, so we don't have enough evidence to reject the null that the populations are identical. We have a huge sample size, so it is not for lack of observations. If there is a difference between the populations, it's small. Recall the median mdex for the post 24/7 intervention (group = 0) is *lower* than the median for the pre 24/7 intervention group. The mean of the post 24/7 group is *higher*. This is a right skewed data set so the median is probably a better measure of center. I still need to do a subgroup analysis of this. 

Adm subgroup:
```{r}
wilcox.test(subset(wb_data, adm == 1)$mdex ~subset(wb_data, adm == 1)$group)
wilcox.test(subset(wb_data, adm == 0)$mdex ~subset(wb_data, adm == 0)$group)

```
When stratified by adm, the subgroups come from different populations (ie: there is an effect due to the intervetion). Recall the descriptive stats, median and mean mdex is shorter in the post 24/7 group for patients that are not admitted. Median and mean mdex is *longer* in the post 24/7 group for patients that are not admitted. 


```{r}
wilcox.test(subset(wb_data, trauma == 1)$mdex ~subset(wb_data, trauma == 1)$group)
wilcox.test(subset(wb_data, trauma == 0)$mdex ~subset(wb_data, trauma == 0)$group)

```
When stratified by trauma, only trauma patients come from different populations (ie: there is an effect due to the intervention in the trauma subgroup). Non-trauma patients in both pre and post groups come from the same population. Median and mean mdex is *shorter* in the post 24/7 group for trauma patients.

```{r}
wilcox.test(subset(wb_data, ctas == 1)$mdex ~subset(wb_data, ctas == 1)$group)
wilcox.test(subset(wb_data, ctas == 2)$mdex ~subset(wb_data, ctas == 2)$group)
wilcox.test(subset(wb_data, ctas == 3)$mdex ~subset(wb_data, ctas == 3)$group)
wilcox.test(subset(wb_data, ctas == 4)$mdex ~subset(wb_data, ctas == 4)$group)
wilcox.test(subset(wb_data, ctas == 5)$mdex ~subset(wb_data, ctas == 5)$group)

```

When stratified by ctas, only ctas4 patients come from different populations (ie: there is an effect due to the intervention in the trauma subgroup). CTAS1, CTAS2, CTAS3, and CTAS5 patients in both pre and post groups come from the same population. Median mdex is longer but mean mdex is shorter in the post 24/7 group of CTAS4 patients. 

```{r}
wilcox.test(subset(wb_data, todseen == 1)$mdex ~subset(wb_data, todseen == 1)$group)
wilcox.test(subset(wb_data, todseen == 2)$mdex ~subset(wb_data, todseen == 2)$group)
wilcox.test(subset(wb_data, todseen == 3)$mdex ~subset(wb_data, todseen == 3)$group)

```
When stratified by todseen, only todseen2 and todseen3 (evening and night) patients come from different populations (ie: there is an effect due to the intervention in the trauma subgroup). Todseen 1 patients (morning) in both pre and post groups come from the same population. The median mdex times are shorter but mean mdex times are longer in the post 24/7 group of both todseen2 and todeen3 patients.  



Table to summarize the Mannn-Whitney U subgroup tests:
```{r}

adm.ctr <- rbind(c(mean(subset(wb_data, adm == 0 & group == 0)$mdex), mean(subset(wb_data, adm == 0 & group == 1)$mdex)), 
               c(median(subset(wb_data, adm == 0 & group == 0)$mdex), median(subset(wb_data, adm == 0 & group ==1)$mdex)), 
               c(mean(subset(wb_data, adm == 1 & group == 0)$mdex), mean(subset(wb_data, adm == 1 & group == 1)$mdex)), 
               c(median(subset(wb_data, adm == 1 & group == 0)$mdex), median(subset(wb_data, adm == 1 & group ==1)$mdex)))

trauma.ctr <- rbind(c(mean(subset(wb_data, trauma == 0 & group == 0)$mdex), mean(subset(wb_data, trauma == 0 & group == 1)$mdex)), 
                  c(median(subset(wb_data, trauma == 0 & group == 0)$mdex), median(subset(wb_data, trauma == 0 & group == 1)$mdex)), 
                  c(mean(subset(wb_data, trauma == 1 & group == 0)$mdex), mean(subset(wb_data, trauma == 1 & group == 1)$mdex)), 
                  c(median(subset(wb_data, trauma == 1 & group == 0)$mdex), median(subset(wb_data, trauma == 1 & group == 1)$mdex)))

ctas.ctr <- rbind(c(mean(subset(wb_data, ctas == 1 & group == 0)$mdex), mean(subset(wb_data, ctas == 1 & group == 1)$mdex)), c(median(subset(wb_data, ctas == 1 & group == 0)$mdex), median(subset(wb_data, ctas == 1 & group == 1)$mdex)), 
                c(mean(subset(wb_data, ctas == 2 & group == 0)$mdex), mean(subset(wb_data, ctas == 2 & group == 1)$mdex)), c(median(subset(wb_data, ctas == 2 & group == 0)$mdex), median(subset(wb_data, ctas == 2 & group == 1)$mdex)), 
                c(mean(subset(wb_data, ctas == 3 & group == 0)$mdex), mean(subset(wb_data, ctas == 3 & group == 1)$mdex)), c(median(subset(wb_data, ctas == 3 & group == 0)$mdex), median(subset(wb_data, ctas == 3 & group == 1)$mdex)), 
                c(mean(subset(wb_data, ctas == 4 & group == 0)$mdex), mean(subset(wb_data, ctas == 4 & group == 1)$mdex)), c(median(subset(wb_data, ctas == 4 & group == 0)$mdex), median(subset(wb_data, ctas == 4 & group == 1)$mdex)),  
                c(mean(subset(wb_data, ctas == 5 & group == 0)$mdex), mean(subset(wb_data, ctas == 5 & group == 1)$mdex)), c(median(subset(wb_data, ctas == 5 & group == 0)$mdex), median(subset(wb_data, ctas == 5 & group == 1)$mdex)))

todseen.ctr <- rbind(c(mean(subset(wb_data, todseen == 1 & group == 0)$mdex), mean(subset(wb_data, todseen == 1 & group == 1)$mdex)), 
                     c(median(subset(wb_data, todseen == 1 & group == 0)$mdex), median(subset(wb_data, todseen == 1 & group == 1)$mdex)), 
                     c(mean(subset(wb_data, todseen == 2 & group == 0)$mdex), mean(subset(wb_data, todseen == 2 & group == 1)$mdex)), 
                     c(median(subset(wb_data, todseen == 2 & group == 0)$mdex), median(subset(wb_data, todseen == 2 & group == 1)$mdex)), 
                     c(mean(subset(wb_data, todseen == 3 & group == 0)$mdex), mean(subset(wb_data, todseen == 3 & group == 1)$mdex)), 
                     c(median(subset(wb_data, todseen == 3 & group == 0)$mdex), median(subset(wb_data, todseen == 3 & group == 1)$mdex)))

all.ctr <- rbind(adm.ctr, trauma.ctr, ctas.ctr, todseen.ctr)

all.wh.p <- c(wilcox.test(subset(wb_data, adm == 1)$mdex ~subset(wb_data, adm == 1)$group)$p.value, NULL, wilcox.test(subset(wb_data, adm == 0)$mdex ~subset(wb_data, adm == 0)$group)$p.value, NULL, wilcox.test(subset(wb_data, trauma == 1)$mdex ~subset(wb_data, trauma == 1)$group)$p.value, NULL, wilcox.test(subset(wb_data, trauma == 0)$mdex ~subset(wb_data, trauma == 0)$group)$p.value, NULL, wilcox.test(subset(wb_data, ctas == 1)$mdex ~subset(wb_data, ctas == 1)$group)$p.value, NULL, wilcox.test(subset(wb_data, ctas == 2)$mdex ~subset(wb_data, ctas == 2)$group)$p.value, NULL, wilcox.test(subset(wb_data, ctas == 3)$mdex ~subset(wb_data, ctas == 3)$group)$p.value, NULL, wilcox.test(subset(wb_data, ctas == 4)$mdex ~subset(wb_data, ctas == 4)$group)$p.value, NULL, wilcox.test(subset(wb_data, ctas == 5)$mdex ~subset(wb_data, ctas == 5)$group)$p.value, NULL, wilcox.test(subset(wb_data, todseen == 1)$mdex ~subset(wb_data, todseen == 1)$group)$p.value, NULL, wilcox.test(subset(wb_data, todseen == 2)$mdex ~subset(wb_data, todseen == 2)$group)$p.value, NULL, wilcox.test(subset(wb_data, todseen == 3)$mdex ~subset(wb_data, todseen == 3)$group)$p.value, NULL)

all.w.df <- as.data.frame(cbind(c("adm0", "", "adm1", "", "trauma0", "", "trauma1", "", "ctas1", "", "ctas2", "", "ctas3", "", "ctas4", "", "ctas5", "", "todseen1", "", "todseen2", "", "todseen3", ""), p.value = rep(all.wh.p, each = 2), rep(c("mean", "median"), 12), all.ctr))


all.w.df$V5 <- round(as.numeric(as.character(all.w.df$V5)), 1)
all.w.df$V4 <- round(as.numeric(as.character(all.w.df$V4)), 1)
all.w.df$p.value <- round(as.numeric(as.character(all.w.df$p.value)), 5)
all.w.df$improvement <- ifelse(all.w.df[ , 4] - all.w.df[ , 5] < 0, "Yes", "No")

colnames(all.w.df) <- c("Subgroup", "M-W p value", "Measure of Center", "Post 24/7", "Pre 24/7", "Improvement?")


library(formattable)
formattable(all.w.df)


```
###Overall Mann-Whitney U Test results

No effect on mdex due to intervention, though the means and medians suggest that the intervention may decrease mdex time. The clearest subgroup effects (p value < 0.05 and a change in mean and median in the same direction) are in Adm0, Adm1, and Trauma1. In Adm0 and Trauma1, the mean and median mdex time decreased. In Adm1, the mdex time increased. 

A simple p value doesn't tell us much apart from the probability of getting out data given the null is true. Maybe try to fit some models and see if we can get more information out of it. 


##Cox Semi-Parametric Regression
```{r}

library(survival)
surv.mdex <- Surv(wb_data$mdex)

#cox semis, uni, all multi, and just ctas multi
g.uni.cox <- coxph(data = wb_data, formula = Surv(mdex) ~ group)
summary(g.uni.cox)
#2.7% to 5.5% faster

all.multi.cox <- coxph(surv.mdex ~ wb_data$group + wb_data$ctas + wb_data$trauma + wb_data$todseen + wb_data$adm)
summary(all.multi.cox)

g.c.multi.cox <- coxph(surv.mdex ~ wb_data$group + wb_data$ctas)
summary(g.c.multi.cox)
#can also stratify by ctas, that just gives us one coefficient for group, none for ctas
coxph(surv.mdex ~ wb_data$group + strata(wb_data$ctas))

#if we want to look at sub group analysis, or actually interaction terms
g.c.int.multi.cox <- coxph(data = wb_data, formula = Surv(mdex) ~ group + group*ctas)
summary(g.c.int.multi.cox)
#how is group*ctas1 different than ctas1? Check the interactions of two categorical notes. Oh yeah, ctas on it's own is the effect of ctas regardless of group, ctas*group is the effect of ctas in group 1 (or vice versa, their effect together when both present)
  #This output tells us that the biggest group effect is in ctas1 (6.7%), then ctas2 and 3 are pretty big (5.4% and 5.9%), then ctas4 sees hardly a group effect, and ctas5 is 2%

all.int.multi.cox <- coxph(data = wb_data, formula = Surv(mdex) ~ group + group*trauma + group*adm)
summary(all.int.multi.cox)
```
That was fun! The univariate model suggests that mdex is 2.7% to 5.5% slower in the intervention group. But before I get too excited, I should probably check the proportional hazards assumption **ominous music plays in the background**


```{r}
g.cox.test <- cox.zph(g.uni.cox)
g.cox.test
cox.zph(g.c.multi.cox)
cox.zph(all.multi.cox)
g.c.int.cox.test <- cox.zph(g.c.int.multi.cox)
g.c.int.cox.test

library(survminer)

ggcoxzph(g.cox.test)

lm(data = wb_data, mdex ~ group)

result.surv.g0 <- survfit(Surv(wb_data$mdex) ~ wb_data$group, subset = {wb_data$group == 0})
time.g0 <- result.surv.g0$time
surv.g0 <- result.surv.g0$surv
cloglog.g0 <- log(-log(surv.g0))
logtime.g0 <- log(time.g0)

result.surv.g1 <- survfit(Surv(wb_data$mdex) ~ wb_data$group, subset = {wb_data$group == 1})
time.g1 <- result.surv.g1$time
surv.g1 <- result.surv.g1$surv
cloglog.g1 <- log(-log(surv.g1))
logtime.g1 <- log(time.g1)

plot(cloglog.g0 ~ logtime.g0, type="s", col="blue", lwd=2)
lines(cloglog.g1 ~ logtime.g1, col="red", lwd=2, type="s")
legend("bottomright", legend=c("Post 24/7", "Pre 24/7"), col=c("blue","red"), lwd=2)
#they cross a lot. Would need to allow it to vary with time.

#looking for time variable, just following the textbook
#group.n <- rep(0, nrow(wb_data))
#group.n[wb_data$group == "1"] <- 1
#result.247 <- coxph(Surv(wb_data$mdex) ~ group.n)
#result.247

#result.247.tt <- coxph(Surv(wb_data$mdex) ~ group.n + tt(group.n), tt=function(x,t, ...) x*log(t))
#result.247.tt
#gives me an error for infinity

#group.n <- rep(0, nrow(data_under_1000))
#group.n[data_under_1000$group == "1"] <- 1
#result.247 <- coxph(Surv(data_under_1000$mdex) ~ group.n)
#result.247

#result.247.tt <- coxph(Surv(data_under_1000$mdex) ~ group.n + tt(group.n), tt=function(x,t, ...) x*log(t))
#result.247.tt
#still can't get it to work, no error, but takes more than 5 minutes to run. Maybe try again later. 


#Here's if we want to check with covariates, I tried with a coulple and it still comes out super crossy
#result.surv.g0 <- survfit(Surv(wb_data$mdex) ~ wb_data$group + wb_data$adm, subset = {wb_data$group == 0})
#time.g0 <- result.surv.g0$time
#surv.g0 <- result.surv.g0$surv
#cloglog.g0 <- log(-log(surv.g0))
#logtime.g0 <- log(time.g0)

#result.surv.g1 <- survfit(Surv(wb_data$mdex) ~ wb_data$group + wb_data$adm, subset = {wb_data$group == 1})
#time.g1 <- result.surv.g1$time
#surv.g1 <- result.surv.g1$surv
#cloglog.g1 <- log(-log(surv.g1))
#logtime.g1 <- log(time.g1)

#plot(cloglog.g0 ~ logtime.g0, type="s", col="blue", lwd=2)
#lines(cloglog.g1 ~ logtime.g1, col="red", lwd=2, type="s")
#legend("bottomright", legend=c("Pre 24/7", "Post 24/7"), col=c("blue","red"), lwd=2)

#maybe check from plots for linearity.

```
Cox assumes proportional hazards. We might not be able to assume this. 

The coxzph() function for each regression gives p values below 0.05, which means the hazard functions are not parrallel (ie: not proportional).

The graph shows them crossing about a billion times. Actually only three times. That's bad. When I follow a method I found in a textbook to determine the time varying hazard ratio, my R either has an "inf" error or works really hard and never finds something. I'm guessing it's because it's trying to estimate a higher order polynomial (recall the lines cross 3 times) and it's just computationally intensive. Or I'm doing it wrong. The time varying hazard ratio would have to switch signs 4 times. That makes me suspicious. It might be that the covariates are much stronger determinants than group. Also, if I step back and think about it, the lines cross so much because they are so close together. They are nearly parrallel, but they cross because the effect of group is so weak. 

I also did a cloglog vs logtime plot of each individual ctas level (ie: subgroup check of porportional hazards) and they were equally messy and crossy.

I could also do some plots to check the linearity, but I'll hold off for now since the hazards are so clearly no proportional. 

##Weibel model
```{r}
library(Hmisc)
weib.km <- survfit(Surv(wb_data$mdex) ~ 1)

survEst <- weib.km$surv
survTime <- weib.km$time 
logLogSurvEst <- log(-log(survEst)) 
logSurvTime <- log(survTime)

logSurvTime <- ifelse(logSurvTime == -Inf, 0, logSurvTime)
logLogSurvEst <- ifelse(logLogSurvEst == Inf, 2.5, logLogSurvEst)
describe(logSurvTime)
describe(logLogSurvEst)

plot(logLogSurvEst ~ logSurvTime)
result.lm <- lm(logLogSurvEst ~ logSurvTime) 
abline(result.lm)
#This shows that a weibel is not apporpriate.

```
Weibell is not appropriate. That plot would need to be linear for Weibell to be appropriate. 

So those two models don't work. Maybe that means no model. We can look at it in Kaplan-Meier. KM does not have an underlying model, which is nice! The drawback is that KM can only tell us about the difference, and cannot really tell us about the magnitude of the difference. 

##Kaplan-Meier
```{r}

library(ggfortify)

#km
g.km <- survfit(surv.mdex ~ wb_data$group)
plot(g.km, xlab="Time in Minutes", ylab="Probability of Still Being with Md", col=c("blue", "red"), lwd=2, conf.int = TRUE)
legend("topright", legend=c("Post 24/7", "Pre 24/7"), col=c("blue","red") , lwd=2)
title("K-M for mdex")

survdiff(Surv(wb_data$mdex) ~ wb_data$group, rho = 1)
#congrats, there's a difference, but what's the magnitude? That's the limitation of KM


#Can also zoom into certain sections of the graph
plot(g.km, xlab="Time in Minutes", ylab="Probability of Still Being with Md", col=c("blue", "red"), lwd=2, xlim = c(0, 500), conf.int = TRUE)
legend("topright", legend=c("Post 24/7", "Pre 24/7"), col=c("blue","red") , lwd=2)
title(main = "K-M for mdex", sub = "zoomed in on mdex < 500 minutes")

```
You can see in the full KM graph that the red line dips below the blue line between roughly 500 and 1500 minutes. That means that in that region, the pre 24/7 is faster. However when we zoom in to under 500 minutes, the blue line is below the red line, which means that the post 24/7 is faster. This is compatible with the first couple of histograms at the start of this document where we saw that the post 24/7 group has more observations with very small mdex. The mean for the post group is lower, but the median is higher. So from the graph, we can see that the first 50% of processes occur faster in the post group, but then the pre group gets faster. 

It may not be appropriate to do a log ranked test because the curves cross. "Statistical Inference Methods for Two Crossing Survival Curves: A Comparison of Methods (Huimin Li, 1 Dong Han, 1 Yawen Hou, 2 Huilin Chen, 1 and Zheng Chen 1; 2015)" suggests using Nyeman's smooth tests or a two stage procedure would be appropriate. I don't know how to do those and I couldn't find an up to date R package for them. 

I use the Peto & Peto modification of the Gehan-Wilcoxon logranked test because it gives more weight to earlier time points. It is also better for when the proportional hazards assumption does not hold. It's probably not appropriate for crossing lines, but I ran it for exploratory reasons. On the entire dataset, it gives a p = 0.08, there isn't enough evidence to say they are not the same curves. Recall that the mean for the post group is higher, but the median is lower. Also, when there is no loss to follow up, I think the logranked test simplifies to the Mann-Whitney U. 

We can look as K-M curves for each level of CTAS:
```{r}

data_ctas1 <- subset(wb_data, ctas ==1)
data_ctas2 <- subset(wb_data, ctas ==2)
data_ctas3 <- subset(wb_data, ctas ==3)
data_ctas4 <- subset(wb_data, ctas ==4)
data_ctas5 <- subset(wb_data, ctas ==5)

survdiff(Surv(wb_data$mdex) ~ wb_data$group + strata(wb_data$ctas), rho = 1)

g.km.ctas1 <- survfit(Surv(data_ctas1$mdex) ~ data_ctas1$group)
plot(g.km.ctas1, xlab="Time in Minutes", ylab="Probability of Still Being with Md", col=c("blue", "red"), lwd=2, conf.int = TRUE)
legend("topright", legend=c("Post 24/7", "Pre 24/7"), col=c("blue","red") , lwd=2)
title("K-M for mdex of CTAS1")

plot(g.km.ctas1, xlab="Time in Minutes", ylab="Probability of Still Being with Md", col=c("blue", "red"), lwd=2, xlim = c(0, 1000), conf.int = TRUE)
legend("topright", legend=c("Post 24/7", "Pre 24/7"), col=c("blue","red") , lwd=2)
title("K-M for mdex of CTAS1", sub = "zoomed in on mdex < 1000 minutes")

survdiff(Surv(data_ctas1$mdex) ~ data_ctas1$group, rho= 1)


g.km.ctas2 <- survfit(Surv(data_ctas2$mdex) ~ data_ctas2$group)
plot(g.km.ctas2, xlab="Time in Minutes", ylab="Probability of Still Being with Md", col=c("blue", "red"), lwd=2, conf.int = TRUE)
legend("topright", legend=c("Post 24/7", "Pre 24/7"), col=c("blue","red") , lwd=2)
title("K-M for mdex of CTAS2")

plot(g.km.ctas2, xlab="Time in Minutes", ylab="Probability of Still Being with Md", col=c("blue", "red"), lwd=2, xlim = c(0, 500), conf.int = TRUE)
legend("topright", legend=c("Post 24/7", "Pre 24/7"), col=c("blue","red") , lwd=2)
title("K-M for mdex of CTAS2", sub= "zoomed in on mdex < 500 minutes")

survdiff(Surv(data_ctas2$mdex) ~ data_ctas2$group, rho= 1)


g.km.ctas3 <- survfit(Surv(data_ctas3$mdex) ~ data_ctas3$group)
plot(g.km.ctas3, xlab="Time in Minutes", ylab="Probability of Still Being with Md", col=c("blue", "red"), lwd=2, conf.int = TRUE)
legend("topright", legend=c("Post 24/7", "Pre 24/7"), col=c("blue","red") , lwd=2)
title("K-M for mdex of CTAS3")

plot(g.km.ctas3, xlab="Time in Minutes", ylab="Probability of Still Being with Md", col=c("blue", "red"), lwd=2, xlim = c(0, 300), conf.int = TRUE)
legend("topright", legend=c("Post 24/7", "Pre 24/7"), col=c("blue","red") , lwd=2)
title("K-M for mdex of CTAS3", sub = "zoomed in on mdex < 300 minutes")

survdiff(Surv(data_ctas3$mdex) ~ data_ctas3$group, rho= 1)

g.km.ctas4 <- survfit(Surv(data_ctas4$mdex) ~ data_ctas4$group)
plot(g.km.ctas4, xlab="Time in Minutes", ylab="Probability of Still Being with Md", col=c("blue", "red"), lwd=2, conf.int = TRUE)
legend("topright", legend=c("Post 24/7", "Pre 24/7"), col=c("blue","red") , lwd=2)
title("K-M for mdex of CTAS4")

plot(g.km.ctas4, xlab="Time in Minutes", ylab="Probability of Still Being with Md", col=c("blue", "red"), lwd=2, xlim = c(0, 300), conf.int = TRUE)
legend("topright", legend=c("Post 24/7", "Pre 24/7"), col=c("blue","red") , lwd=2)
title("K-M for mdex of CTAS4", sub = "zoomed in on mdex < 300 minutes")

survdiff(Surv(data_ctas4$mdex) ~ data_ctas4$group, rho= 1)

g.km.ctas5 <- survfit(Surv(data_ctas5$mdex) ~ data_ctas5$group)
plot(g.km.ctas5, xlab="Time in Minutes", ylab="Probability of Still Being with Md", col=c("blue", "red"), lwd=2, conf.int = TRUE)
legend("topright", legend=c("Post 24/7", "Pre 24/7"), col=c("blue","red") , lwd=2)
title("K-M for mdex of CTAS5")

plot(g.km.ctas5, xlab="Time in Minutes", ylab="Probability of Still Being with Md", col=c("blue", "red"), lwd=2, xlim = c(0,500), conf.int = TRUE)
legend("topright", legend=c("Post 24/7", "Pre 24/7"), col=c("blue","red") , lwd=2)
title("K-M for mdex of CTAS5", sub = "zoomed in on mdex < 500")

survdiff(Surv(data_ctas5$mdex) ~ data_ctas5$group, rho= 1)

table1(~ trauma  + adm + todseen + mdex | ctas*group, data = table1_data_na)

```
A quick visual inspection shows CTAS2 and CTAS3 have the clearest benefits of 24/7. CTAS1 has the switching of effect and CTAS4 and 5 are less clear. When you zoom in, you can see that most of them cross, with the post group being lower under about 400 minutes and then the pre group being lower after that. 

CTAS1: The survival curves cross. Post is below for the most part for mdex < 1000 and then pre is below for the most part after that. Post median and mean are higher. Lines cross and a p = 0.5

CTAS2: We can see pre is below for probably the entire curve. Post median and mean are higher p = 0.3

CTAS3: Between 100 and 250, post is slightly below and then after 250, pre is below. Post mean is higher, but post median is lower. p = 0.6 

CTAS4: Post is slightly below until 250 and then pre is slighty below after that. Post mean is higher, but post median is lower. p = 2e-05

CTAS5: Post is slightly below from 50 until about 250, and then pre is below after that. Post mean is higher, but post median is lower. p = 0.6

KM CTAS sub group analysis conclusion: The intervention may decrease median mdex in CTAS3, CTAS4 and CTAS5 (may be conclusive for CTAS3). The intervention may increase mdex time in CTAS1 and CTAS2. 


Subgroup of Adm:
```{r}

data_adm0 <- subset(wb_data, adm ==0)
data_adm1 <- subset(wb_data, adm ==1)

survdiff(Surv(wb_data$mdex) ~ wb_data$group + strata(wb_data$adm), rho = 1)

g.km.adm0 <- survfit(Surv(data_adm0$mdex) ~ data_adm0$group)
plot(g.km.adm0, xlab="Time in Minutes", ylab="Probability of Still Being with Md", col=c("blue", "red"), lwd=2, conf.int = TRUE)
legend("topright", legend=c("Post 24/7", "Pre 24/7"), col=c("blue","red") , lwd=2)
title("K-M for mdex of Adm = 0")

plot(g.km.adm0, xlab="Time in Minutes", ylab="Probability of Still Being with Md", col=c("blue", "red"), lwd=2, xlim = c(0, 900), conf.int = TRUE)
legend("topright", legend=c("Post 24/7", "Pre 24/7"), col=c("blue","red") , lwd=2)
title("K-M for mdex of Adm = 0", sub = "zoomed in on mdex < 800")

survdiff(Surv(data_adm0$mdex) ~ data_adm0$group, rho = 1)

g.km.adm1 <- survfit(Surv(data_adm1$mdex) ~ data_adm1$group)
plot(g.km.adm1, xlab="Time in Minutes", ylab="Probability of Still Being with Md", col=c("blue", "red"), lwd=2, conf.int = TRUE)
legend("topright", legend=c("Post 24/7", "Pre 24/7"), col=c("blue","red") , lwd=2, box.lty=0)
title("K-M for mdex of Adm = 1 all data")

plot(g.km.adm1, xlab="Time in Minutes", ylab="Probability of Still Being with Md", col=c("blue", "red"), lwd=2, xlim = c(0, 500), conf.int = TRUE)
legend("topright", legend=c("Post 24/7", "Pre 24/7"), col=c("blue","red") , lwd=2, box.lty=0)
title("K-M for mdex of Adm = 1 all data")

survdiff(Surv(data_adm1$mdex) ~ data_adm1$group, rho = 1)


table1(~ trauma + ctas + todseen + mdex | adm*group, data = table1_data_na)

```
Not admitted (Adm = 0): Looks like post is below for the entire curve. The post median and mean are both lower. p = <2e-16 

Admitted (Adm = 1): Looks like pre is below for the entire curve. The post median and mean are both higher. p = <2e-16 

KM Adm sub group analysis conclusion: The intervention increases median mdex in those who are admitted to the hospital (adm = 1). Otherwise, the intervention decreases median mdex for those not admittd (adm = 0). 

Subgroup of Trauma:
```{r}
data_tr0 <- subset(wb_data, trauma ==0)
data_tr1 <- subset(wb_data, trauma ==1)

survdiff(Surv(wb_data$mdex) ~ wb_data$group + strata(wb_data$trauma), rho = 1)

g.km.tr0 <- survfit(Surv(data_tr0$mdex) ~ data_tr0$group)
plot(g.km.tr0, xlab="Time in Minutes", ylab="Probability of Still Being with Md", col=c("blue", "red"), lwd=2, conf.int = TRUE)
legend("topright", legend=c("Post 24/7", "Pre 24/7"), col=c("blue","red") , lwd=2)
title("K-M for mdex of Trauma = 0")

plot(g.km.tr0, xlab="Time in Minutes", ylab="Probability of Still Being with Md", col=c("blue", "red"), lwd=2, xlim = c(0, 500), conf.int = TRUE)
legend("topright", legend=c("Post 24/7", "Pre 24/7"), col=c("blue","red") , lwd=2)
title("K-M for mdex of Trauma = 0", sub = "zoomed in on mdex < 500 minutes")

survdiff(Surv(data_tr0$mdex) ~ data_tr0$group, rho = 1)

g.km.tr1 <- survfit(Surv(data_tr1$mdex) ~ data_tr1$group)
plot(g.km.tr1, xlab="Time in Minutes", ylab="Probability of Still Being with Md", col=c("blue", "red"), lwd=2, conf.int = TRUE)
legend("topright", legend=c("Post 24/7", "Pre 24/7"), col=c("blue","red") , lwd=2, box.lty=0)
title("K-M for mdex of Trauma = 1")

plot(g.km.tr1, xlab="Time in Minutes", ylab="Probability of Still Being with Md", col=c("blue", "red"), lwd=2, xlim = c(0, 500), conf.int = TRUE)
legend("topright", legend=c("Post 24/7", "Pre 24/7"), col=c("blue","red") , lwd=2, box.lty=0)
title("K-M for mdex of Trauma = 1", sub = "zoomed in on mdex < 500 minutes")

survdiff(Surv(data_tr1$mdex) ~ data_tr1$group, rho = 1)

table1(~ adm + todseen + ctas + mdex | trauma*group, data = table1_data_na)

```
Trauma = 0: Post is below pre until about 250 after which pre is below. Post mean is higher and post median is lower. p = 0.8

Trauma = 1: Post is below until about 500. It looks like pre might get below after that, but not by much. Post mean and median are lower. p = 1e-07  

KM Trauma subgroup conclusion: It looks like the intervention decreases the mdex time in trauma patients. Note: there is a much larger sample size for Trauma = 0. 

```{r}
data_to1 <- subset(wb_data, todseen ==1)
data_to2 <- subset(wb_data, todseen ==2)
data_to3 <- subset(wb_data, todseen ==3)

survdiff(Surv(wb_data$mdex) ~ wb_data$group + strata(wb_data$todseen), rho = 1)

g.km.to1 <- survfit(Surv(data_to1$mdex) ~ data_to1$group)
plot(g.km.to1, xlab="Time in Minutes", ylab="Probability of Still Being with Md", col=c("blue", "red"), lwd=2, conf.int = TRUE)
legend("topright", legend=c("Post 24/7", "Pre 24/7"), col=c("blue","red") , lwd=2)
title("K-M for mdex of Todseen = 1")

plot(g.km.to1, xlab="Time in Minutes", ylab="Probability of Still Being with Md", col=c("blue", "red"), lwd=2, xlim = c(0, 300), conf.int = TRUE)
legend("topright", legend=c("Post 24/7", "Pre 24/7"), col=c("blue","red") , lwd=2)
title("K-M for mdex of Todseen = 1", sub = "zoomed in on mdex < 300 minutes")

survdiff(Surv(data_to1$mdex) ~ data_to1$group, rho = 1)


g.km.to2 <- survfit(Surv(data_to2$mdex) ~ data_to2$group)
plot(g.km.to2, xlab="Time in Minutes", ylab="Probability of Still Being with Md", col=c("blue", "red"), lwd=2, conf.int = TRUE)
legend("topright", legend=c("Post 24/7", "Pre 24/7"), col=c("blue","red") , lwd=2)
title("K-M for mdex of Todseen = 2")

plot(g.km.to2, xlab="Time in Minutes", ylab="Probability of Still Being with Md", col=c("blue", "red"), lwd=2, xlim = c(0, 400), conf.int = TRUE)
legend("topright", legend=c("Post 24/7", "Pre 24/7"), col=c("blue","red") , lwd=2)
title("K-M for mdex of Todseen = 2", sub = "zoomed in on mdex < 400 minutes")

survdiff(Surv(data_to2$mdex) ~ data_to2$group, rho = 1)

g.km.to3 <- survfit(Surv(data_to3$mdex) ~ data_to3$group)
plot(g.km.to3, xlab="Time in Minutes", ylab="Probability of Still Being with Md", col=c("blue", "red"), lwd=2, conf.int = TRUE)
legend("topright", legend=c("Post 24/7", "Pre 24/7"), col=c("blue","red") , lwd=2)
title("K-M for mdex of Todseen = 3")

plot(g.km.to3, xlab="Time in Minutes", ylab="Probability of Still Being with Md", col=c("blue", "red"), lwd=2, xlim = c(0, 400), conf.int = TRUE)
legend("topright", legend=c("Post 24/7", "Pre 24/7"), col=c("blue","red") , lwd=2)
title("K-M for mdex of Todseen = 3", sub = "zoomed in on mdex < 400 minutes")

survdiff(Surv(data_to3$mdex) ~ data_to3$group, rho = 1)


table1(~ adm + trauma + ctas + mdex | todseen*group, data = table1_data_na)


```
Todseen = 1: Post is barely below between 50 and 250. Pre is below around 300 to 2000. Post mean and median are higher. p = 0.1

Todseen = 2: Post is below up to about 350 and pre is below after that until about 2000. There's a weird hump in post around 1000. Post mean is higher, but the post median is lower. p = 0.01

Todseen = 3: Post is below until about 350, after which pre is slightly below until a little past 200. Post mean is higher, but the post median is lower. p = 0.02

KM Todseen subgroup conclusions: The intervention may increase median mdex in Todseen = 1, but is inconclusive. The intervention decreases median mdex in Todseen = 2 and 3.

###Overall KM results

Very small differences in mdex between the groups. It seem that the post intervention group usually has a smaller median mdex, but that the pre intervention gets "faster" after hitting the median (ie: it is quicker for "longer" cases). The post intervention group is the sprinter that has the fastest 100m and the pre intervention group is slower out of the blocks, but wins the 400m with a strong back half of the race. The intervention is faster up until about ~400 minutes, and then it becomes slower

Intervention may decrease the mdex (mean and median) time for trauma patients and patients that are not admitted. The intervention may increase mdex time in admitted patients. There may be subgroup effects in CTAS and Todseen, but it's hard to say (the evidence isn't as strong and there is the mean and median going in opposite directions post intervention compared to pre intervention).

##Linear Regression

Just looking at plain old linear regressions. The distribution of mdex is clearly not normal (long right tail), but maybe there are enough observations for us to feel comfortable that the CLT has kicked in.
```{r}
g.uni <- lm(data = wb_data, mdex ~ group)
summary(g.uni)
confint(g.uni)

c(22, 17, 12)/374


```
Recall that the intervention is coded as pre 24/7 interventon being group = 1 and post intervention being group = 0. With only group, the model describes the effect of group at -17 minutes (ie: 17 minutes faster in pre 24/7). That's 3.2% to 5.9% longer mdex after the intervention. This is basically a t-test comparing *means*. 

CTAS subgroup effects:
```{r}
g.c.int.multi <- lm(data = wb_data, mdex ~ group + group*ctas)
confint(g.c.int.multi)
```
Explore subgroup effects with group and a ctas interaction term, it shows that group has the greatest absolute effect on the ctas1 level (-34 mins for pre intervention group). It shows that group has an absolute effect of -28 mins in ctas2 and -22 minutes in ctas3. Not much of an effect in ctas4 or ctas5. The CIs are very wide and all of them cross the null. 

Another way to do subgroup analysis is to do linear regressions on each subset of the data.
```{r}
lm(data = subset(wb_data, ctas == 1), mdex ~ group)
lm(data = subset(wb_data, ctas == 2), mdex ~ group)
lm(data = subset(wb_data, ctas == 3), mdex ~ group)
lm(data = subset(wb_data, ctas == 4), mdex ~ group)
lm(data = subset(wb_data, ctas == 5), mdex ~ group)

confint(lm(data = subset(wb_data, ctas == 3), mdex ~ group))
```
You can see this gives the same Point Estimates as the single regression with interaction terms (ie: the group coefficient plus each specific interaction term for the subgroup of interest). Note that the confidence interval is much more narrow with the individuals linear regressions than it is for the interaction term regression. I'm not sure which one is a more accurate representation of the uncertainty, but my instinct is that the wider CIs of the regression with interaction terms is a more honnest/accurate representation of the uncertainty.

Adm subgroup:
```{r}
lm(data = wb_data, mdex ~ group + adm*group)
summary(lm(data = wb_data, mdex ~ group + adm*group))
confint(lm(data = wb_data, mdex ~ group + adm*group))

```
Longer mdex times in post 24/7 group when patient not admitted. Shorter mdex times in post 24/7 group when patient admitted. This is compatible with what we saw in the KM nsubgroup analysis.

Trauma subgroup:
```{r}
lm(data = wb_data, mdex ~ group + trauma*group)
summary(lm(data = wb_data, mdex ~ group + trauma*group))
confint(lm(data = wb_data, mdex ~ group + trauma*group))

```
Longer mdex times in post 24/7 group for non-trauma patient. Shorter mdex times in post 24/7 group for trauma patients. This is compatible with what we saw in the KM subgroup analysis.

Todseen subgroup:
```{r}
lm(data = wb_data, mdex ~ group + todseen*group)
summary(lm(data = wb_data, mdex ~ group + todseen*group))
confint(lm(data = wb_data, mdex ~ group + todseen*group))
```
Longer mdex times in post 24/7 group for todseen = 1.

Can check some other multi regressions and the bic.glm for fun. Further below I check the assumptions 
```{r}
library(MASS)
library(BMA)
lm(data = wb_data, mdex ~ group + ctas + trauma + adm)
summary(lm(data = wb_data, mdex ~ group + ctas + trauma + adm + todseen))
confint(lm(data = wb_data, mdex ~ group + ctas + trauma + adm))


bic.linear <- bic.glm.formula(data = wb_data, f = mdex ~ group + ctas + trauma + adm + todseen, glm.family = gaussian())
summary(bic.linear)
```
"Full up" model has group effect at -11 minutes (ie: 11 minutes longer in the post intervention group). The full model has a higher R (obvously), but recall prediction is not the aim. 

Checking assumptions of linear regressions
```{r}

uni.resid <- data.frame(g.uni$residuals, wb_data$group)


ggplot(data = uni.resid, aes(x = g.uni.residuals)) + 
  geom_histogram() + xlim(0, 4000) +
  labs(title = "Univariate Linear Regression Residuals", x = "lm(mdex ~ group) Residuals", y = "Count")


int.resid <- data.frame(g.c.int.multi$residuals, wb_data$group)


ggplot(data = int.resid, aes(x = g.c.int.multi.residuals)) + 
  geom_histogram() + xlim(0, 4000) +
  labs(title = "Multivariate Interaction Terms Linear Regression Residuals", x = "lm(mdex ~ group + group*ctas) Residuals", y = "Count")

plot(wb_data$group, uni.resid$g.uni.residuals)

```

Relationship is linear between X and Y , i.e., relation is a straight line: Dummy variables (ie: categorical) meet the assumption of linearity by definition, because they creat two data points, and two points define a straight line. There is no such thing as a non-linear relationship for a single variable with only two values. Dummy variables need no linearity assumptions, as they are already linear.

The “errors” (also known as “residuals”) are independent N(0, σ2): Not very normal at all. See the histograms above. 

σ2 is constant throughout the range: Not sure how to check with with dummy variables. 

Conclusion: We can probably assume the CLT has kicked in and the linear regression is pretty robust. That being said, the residuals aren't normally distributed. We can take the information from the linear regression with a grain of salt. We see some effect due to group and it appears to interact with CTAS. We shouldn't get too excited about that precision. Maybe we can look at other models to see what they say. 

Could look at doing a log transformation of mdex. This would be a log-linear model. 

##Log-linear model
```{r}

wb_data$log.mdex <- log(wb_data$mdex)

hist(data = wb_data, wb_data$log.mdex)

#there are some zero values for mdex. See if I can substitute 1 for zero. 
wb_data$log.mdex <- ifelse(wb_data$log.mdex == -Inf, 0, wb_data$log.mdex)

g.log.uni <- lm(data = wb_data, formula = log.mdex ~ group)
g.log.uni
summary(g.log.uni)
exp(g.log.uni$coefficients)
exp(confint(g.log.uni))
#is the intercept allowed to be that different from the actual mean and median? Is that a by-product of the model fit or something?
#notice the summary of the R2, which is attrocious. I guess that would be expected. The "explanatory" variable of group is super weak and explains very little of the variance. Recall that the aim of this exercise is to see what efect group has, not to predict outcome. 

uni.log.resid <- data.frame(g.log.uni$residuals, wb_data$group)
head(uni.log.resid)

ggplot(data = uni.log.resid, aes(x = g.log.uni.residuals)) + 
  geom_histogram() +
  labs(title = "Univariate Log-Linear Regression Residuals", x = "lm(log(mdex) ~ group) Residuals", y = "Count")
#well shit, that loooks great! This satisfies the assumption that the errors are independent

plot(wb_data$group, g.log.uni$residuals)
#this looks good as well. The determinant is categorical, so we are just for the spread to be similar for each level. This looks to be satisfied. The variance appears to be constant accross the range. 

```
Now the 3 assumptions are much more respected (see the graphs), but the R2 has gone down. In this case, group doesn't seem to have an effect (the CI is 0.99, 1.02). Recall group = 0 is the post 24/7 intervention group. 


Now look at log-linear with a ctas interaction term:
```{r}
g.log.ctas.int <- lm(data = wb_data, formula = log.mdex ~ group + ctas*group)
g.log.ctas.int
summary(g.log.ctas.int)
exp(g.log.ctas.int$coefficients)
exp(confint(g.log.ctas.int))

log.int.resid <- data.frame(g.log.ctas.int$residuals, wb_data$group)


ggplot(data = log.int.resid, aes(x = g.log.ctas.int.residuals)) + 
  geom_histogram() + 
  labs(title = "Multivariate Interaction Terms Linear Regression Residuals", x = "lm(mdex ~ group + group*ctas) Residuals", y = "Count")

plot(wb_data$group, log.int.resid$g.log.ctas.int.residuals)
#another good looking couple of plots. 

```
Like in the linear interaction model, group seems to have the stronget effect in CTAS1 (3.8%) and some effect in CTAS2 and 3 (1-2%). Not much of an effect/reverse effect in CTAS4 and 5. Keep in mind, the CIs are all wide and cover the null. All inconclusive, though there may be some interesting effects in CTAS1, and possibly in 2 and 3 (though evidence in 2 and 3 is much less strong).  

Adm subgroup:
```{r}
g.log.adm.int <- lm(data = wb_data, formula = log.mdex ~ group + adm*group)

summary(g.log.adm.int)
exp(g.log.adm.int$coefficients)
exp(confint(g.log.adm.int))
```
Shorter mdex times in post 24/7 group when patient not admitted. Longer mdex times in post 24/7 group when patient admitted. This is compatible with what we saw in the KM and linear regression subgroup analysis.

Trauma subgroup:
```{r}
g.log.tr.int <- lm(data = wb_data, formula = log.mdex ~ group + group*trauma)

summary(g.log.tr.int)
exp(g.log.tr.int$coefficients)
exp(confint(g.log.tr.int))
```
Maybe longer mdex times in post 24/7 group for non-trauma patient, but inconclusive. Shorter mdex times in post 24/7 group for trauma patients. This is compatible with what we saw in the KM and linear regression subgroup analysis.

Todseen subgroup:
```{r}
g.log.to.int <- lm(data = wb_data, formula = log.mdex ~ group + group*todseen)

summary(g.log.to.int)
exp(g.log.to.int$coefficients)
exp(confint(g.log.to.int))
```
Longer mdex times in post 24/7 group for todseend = 1 (morning). Shorter for todseen = 2 and 3. 

Do an everything in and bic:
```{r}
bic.log.linear <- bic.glm.formula(data = wb_data, f = log.mdex ~ group + ctas + trauma + adm + todseen, glm.family = gaussian())
summary(bic.log.linear)
exp(bic.log.linear$mle)

g.log.all.multi <- lm(data = wb_data, formula = log.mdex ~ group + ctas + trauma + adm + todseen)
g.log.all.multi
summary(g.log.all.multi)
exp(g.log.all.multi$coefficients)
exp(confint(g.log.all.multi))

```
The bic keeps group in and says it makes the time slower (i.e.: longer mdex times for group = 1, the pre intervention group). The "everything in" also says that group = 1 makes it slower. I don't really think these are good models for describing the effect of group, but there they are. 

Overall log linear: Most of the subgroup analyses agree with the KM subgroup analyses. The univariable regression also shows a small effect on mdex due to group. 

We can turn mdex into tertile categorical and run an ordinal logistic regression. This loses information and probably is not a good idea. 
```{r}

#cut off for the first tertile
quantile(wb_data$mdex, probs = 1/3)
#cut off for the second tertile
quantile(wb_data$mdex, probs = 2/3)

wb_data$mdex.tert <- cut(wb_data$mdex, breaks = c(-Inf, quantile(wb_data$mdex, probs = 1/3), quantile(wb_data$mdex, probs = 2/3), Inf), labels = c("1","2","3"))

g.uni.ord <- polr(data = wb_data, mdex.tert ~ group)

g.uni.ord.cis <- exp(confint(g.uni.ord))

multi.ord <- polr(data = wb_data, mdex.tert ~ group + ctas + adm + trauma)

multi.ord.cis <- exp(confint(multi.ord))

quantile(wb_data$mdex, probs = c(1/3, 2/3))




```
The cut off between each tertile is 164 minutes and 374 minutes.

Here is a univariate ordinal with just group:
```{r}
g.uni.ord.cis
```
I think this is saying that the intervention makes it more likely to take less time (ie: be in a lower mdex tertile). This fits with what we've seen where the median is smaller for the post 24/7 group. 

With all the measured variables:
```{r}
multi.ord.cis
```
Here again has the intervention making it more likely to take less time (ie: be in a lower tertile)

I don't think it's worth looking into the subgroups here, but we could. 

**Poisson**
For it to be analyzed as poisson, the outcome needs to be counts. This means creating catergories of length of mdex times and counting how many occured in that category. This results in a loss of data. Probably not the best approach and I haven't figured it out yet, but I've started setting it up. Probably not worth exploring anymore. I mostly did it out of curiousity and to see if I could.  

```{r}
#find out where 99.9% of the data happens, this is so I can just stop binning at a certain point
quantile(wb_data$mdex, probs = 0.999)

wb_data$mdex.counts <- cut(wb_data$mdex, breaks = c(-Inf, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400, 2500, 2600, 2700, 2800, 2900, 3000, Inf), labels = c("0:100", "101:200", "201:300", "301:400", "401:500", "501:600", "601:700", "701:800", "801:900", "901:1000", "1001:1100", "1101:1200", "1201:1300", "1301:1400", "1401:1500", "1501:1600",  "1601:1700", "1701:1800", "1801:1900", "1901:2000", "2001:2100", "2101:2200", "2201:2300", "2301:2400", "2401:2500", "2501:2600",  "2601:2700", "2701:2800", "2801:2900", "2901:3000","Over 3000"))

#try making the categories as integers
wb_data$mdex.counts <- cut(wb_data$mdex, breaks = c(-Inf, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000, 2100, 2200, 2300, 2400, 2500, 2600, 2700, 2800, 2900, 3000, Inf), labels = c(1:31))

pois_data <- as.data.frame(table(wb_data$group, wb_data$mdex.counts))
names(pois_data)[1] <- "Group"
names(pois_data)[2] <- "Mdex_Time"
names(pois_data)[3] <- "Reports"
head(pois_data)

#average number of reports per time category for the pre group
mean(subset(pois_data, Group == 0)$Reports)

#rate of reports per time category overall 
sum(pois_data$Reports)/nrow(pois_data)


ggplot(data = pois_data, aes(x = Mdex_Time, y = Reports, group = Group, color = Group)) + geom_line() + geom_point() + theme(axis.text.x = element_text(angle = -45))

mean(subset(wb_data, group == 1)$mdex)
mean(subset(wb_data, group == 0)$mdex)

#the varaince is supposed to equal the mean. So an order of magnitude off. Variance is much bigger
var(subset(wb_data, group == 1)$mdex)
var(subset(wb_data, group == 0)$mdex)


wb_data$mdex.counts <- as.numeric(wb_data$mdex.counts)
nb.g.uni <- glm.nb(data = wb_data, formula = mdex.counts ~ group)
summary(nb.g.uni)
exp(nb.g.uni$coefficients)
exp(confint(nb.g.uni))



```



