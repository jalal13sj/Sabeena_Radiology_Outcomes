---
title: "247_data_analysis_for_Sabeena"
author: "Marshall"
date: '2019-05-02'
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,          # don't show code
  warning = FALSE,       # don't show warnings
  message = FALSE,       # don't show messages (less serious warnings)
  cache = FALSE,         # set to TRUE to save results from last compilation
  fig.align = "center",   # center figures
  fig.asp = 1,          # fig.aspect ratio
  fig.width = 5       # fig width
)

```



```{r}
setwd("/Users/macbook/Documents/McGill School/Sabeena_Radiology_Outcomes")

#this data has the blank rows and "all-but-id" blank rows removed. It also has extrat binary colmns for the categorical variables for use in winbugs
wb_data <- read.csv("247_data_no_NA_GOOD.csv")
wb_data_na <- read.csv("247_data_some_NA_GOOD.csv")

wb_data$X <- NULL
wb_data_na$X <- NULL

#set factors to factors
wb_data$ctas1 <- as.factor(wb_data$ctas1)
wb_data$ctas2 <- as.factor(wb_data$ctas2)
wb_data$ctas3 <- as.factor(wb_data$ctas3)
wb_data$ctas4 <- as.factor(wb_data$ctas4)
wb_data$ctas5 <- as.factor(wb_data$ctas5)
wb_data$ctas <- as.factor(wb_data$ctas)
wb_data$todseen <- as.factor(wb_data$todseen)
wb_data$todseen1 <- as.factor(wb_data$todseen1)
wb_data$todseen2 <- as.factor(wb_data$todseen2)
wb_data$todseen3 <- as.factor(wb_data$todseen3)
wb_data$group <- as.factor(wb_data$group)
wb_data$imaging <- as.factor(wb_data$imaging)
wb_data$trauma <- as.factor(wb_data$trauma)
wb_data$adm <- as.factor(wb_data$adm)

#repeat with na
wb_data_na$ctas1 <- as.factor(wb_data_na$ctas1)
wb_data_na$ctas2 <- as.factor(wb_data_na$ctas2)
wb_data_na$ctas3 <- as.factor(wb_data_na$ctas3)
wb_data_na$ctas4 <- as.factor(wb_data_na$ctas4)
wb_data_na$ctas5 <- as.factor(wb_data_na$ctas5)
wb_data_na$ctas <- as.factor(wb_data_na$ctas)
wb_data_na$todseen <- as.factor(wb_data_na$todseen)
wb_data_na$todseen1 <- as.factor(wb_data_na$todseen1)
wb_data_na$todseen2 <- as.factor(wb_data_na$todseen2)
wb_data_na$todseen3 <- as.factor(wb_data_na$todseen3)
wb_data_na$group <- as.factor(wb_data_na$group)
wb_data_na$imaging <- as.factor(wb_data_na$imaging)
wb_data_na$trauma <- as.factor(wb_data_na$trauma)
wb_data_na$adm <- as.factor(wb_data_na$adm)

library(ggplot2)

```

Checking out the distribution of turn around time (mdex). 

```{r}

ggplot(data = wb_data_na, aes(x = mdex, color = group)) + 
  geom_histogram(binwidth = 200, alpha = 0.2, position = "identity", fill = "white") +
  labs(title = "Turn Around Time Distribution by Group", color = "Group", x = "Turn Around Time (minutes)", y = "Count") +
  scale_color_discrete(name = "Group", labels = c("pre-24/7","post 24/7"))
#looks like poisson, looks like group 1 and 2 have extreme observations

#look at the 0-1000 mdex range
ggplot(data = wb_data_na, aes(x = mdex, color = group)) + 
  geom_histogram(binwidth = 50, alpha = 0.2, position = "identity", fill = "white") + xlim(0, 1000) +
  labs(title = "Turn Around Time Distribution by Group", subtitle = "TAT < 1000 mins", color = "Group", x = "Turn Around Time (minutes)", y = "Count") +
  scale_color_discrete(name = "Group", labels = c("pre-24/7","post 24/7"))

#the 95th quantil is this
#quantile(wb_data_na$mdex, 0.95, na.rm = T)
#mean(wb_data_na$mdex, na.rm = T)
#sd(wb_data_na$mdex, na.rm = T)
#mean is smaller than the sd...check for overdispersion later
```

It looks like a poisson distribution. There are no negative values, it is a count of minutes, most counts are small but they can go out to infinity, not many ...other things to justify poisson. What is it assuming? Something about low homogeneous intensity, in that they occur at random and have the same force driving them or somthing. 


Take a look at the times in each group.
```{r}

ggplot(data = wb_data_na, aes(x = group, y = mdex)) + geom_boxplot() +
  labs(title = "Turn Around Time by Group", x = "Group", y = "Turn Around Time (minutes)") +
  scale_x_discrete(labels = c("pre 24/7", "post 24/7"))

ggplot(data = wb_data_na, aes(x = group, y = mdex)) + geom_boxplot(outlier.shape = NA) +
  scale_y_continuous(limits = c(0, 600)) +
  labs(title = "Turn Around Time by Group", subtitle = "Outliers Removed", x = "Group", y = "Turn Around Time (minutes)") +
  scale_x_discrete(labels = c("pre 24/7", "post 24/7"))

var(wb_data$mdex)
mean(wb_data$mdex)
```
It doesn't look like a huge difference between the groups. 


**Table 1 and Potential Confounding**
Let's look into potential confounders. See which variables appear to have a relationship with the intervention (group) AND with the outcome (turn around time, labelled "mdex").

Take a quick look at "Table 1" stratified by group to see if there are any imbalances of variables between the groups. An imbalance between groups would suggest a relationship with the group. 
```{r}
#install.packages("table1")
library(table1)


#manipulate data set for Table 1, wont do it now, but if the table should be nicer, then we can label all the categories
table1_data_na <- wb_data_na
table1_data_na$group <- factor(table1_data_na$group, levels = c(0,1), labels = c("pre 24/7", "post 24/7"))
table1_data_na$trauma <- factor(table1_data_na$trauma, levels = c(0,1), labels = c("Non-Trauma Pt", "Trauma Pt"))
table1_data_na$todseen <- factor(table1_data_na$todseen, levels = c(1,2,3), labels = c("Morning", "Evening", "Night"))
table1_data_na$imaging <- factor(table1_data_na$imaging, levels = c(0,1), labels = c("No Imaging", "Imaging Done"))
table1_data_na$adm <- factor(table1_data_na$adm, levels = c(0,1), labels = c("Not Admitted", "Admitted"))
table1_data_na$ctas <- factor(table1_data_na$ctas, levels = c(1,2,3,4,5), labels = c("Dead/Resus", 2, 3, 4, "Almost Normal"))

table1(~ ctas + imaging + adm + todseen + trauma + mdex | group, data = table1_data_na)
```
Everything looks pretty balanced. A couple of spots that have a difference of 1.2% between the groups, but most are less than 1%.
Side note: we can see the median and mean for each group. We can also see Where the missing data is. It's about 5% of the mdex, 5% of todseen, and less than 1% of the trauma.


Can sub-stratify by trauma and ctas if we want. I do that because those might be the least balanced of all the variables (I do proportion tests further down).
```{r}
table1(~ ctas + imaging + adm + todseen + mdex | group*trauma, data = table1_data_na)

table1(~ trauma + imaging + adm + todseen + mdex | group*ctas, data = table1_data_na)
```
Still looking very balanced. 

When stratified by tauma: CTAS maybe has a couple of spots that are between 1% and 1.5% different. Imaging and Adm have spots with 1.2% difference.  

When stratified by ctas: there are some spots where it's 3% different. But now we're really slicing and dicing. 



If we REALLY want to look hard, we can look at each level of each variable and see the propotion that is in each group. Perfect balance (and no relationship with group) would be 0.5, so we can do a bunch of tests of propotion vs the null of 0.5. I'm not sure this adds a lot of value since the n is so large, the CIs are very tight and some of them end up not covering the null even though the proportion is something like 0.51.
```{r}
#check columns proportions, not just overall
c.table <- table(table1_data_na$group, table1_data_na$ctas)
round(prop.table(c.table, 2), 3)
pt.ctas1 <- prop.test(c.table[2,1], sum(c.table[1:2,1]), p = 0.5)
pt.ctas2 <-  prop.test(c.table[2,2], sum(c.table[1:2,2]), p = 0.5)
pt.ctas3 <-  prop.test(c.table[2,3], sum(c.table[1:2,3]), p = 0.5)
pt.ctas4 <-  prop.test(c.table[2,4], sum(c.table[1:2,4]), p = 0.5)
pt.ctas5 <-  prop.test(c.table[2,5], sum(c.table[1:2,5]), p = 0.5)


to.table <- table(table1_data_na$group, table1_data_na$todseen)
round(prop.table(to.table, 2), 3)
pt.to1 <- prop.test(to.table[2,1], sum(to.table[1:2,1]), p = 0.5)
pt.tos2 <-  prop.test(to.table[2,2], sum(to.table[1:2,2]), p = 0.5)
pt.to3 <-  prop.test(to.table[2,3], sum(to.table[1:2,3]), p = 0.5)


i.table <- table(table1_data_na$group, table1_data_na$imaging)
round(prop.table(i.table, 2), 3)
pt.i0 <- prop.test(i.table[2,1], sum(i.table[1:2,1]), p = 0.5)
pt.i1 <-  prop.test(i.table[2,2], sum(i.table[1:2,2]), p = 0.5)

a.table <- table(table1_data_na$group, table1_data_na$adm)
round(prop.table(a.table, 2), 3)
pt.a0 <- prop.test(a.table[2,1], sum(a.table[1:2,1]), p = 0.5)
pt.a1 <- prop.test(a.table[2,2], sum(a.table[1:2,2]), p = 0.5)

tr.table <- table(table1_data_na$group, table1_data_na$trauma)
round(prop.table(tr.table, 2), 3)
pt.tr0 <- prop.test(tr.table[2,1], sum(tr.table[1:2,1]), p = 0.5)
pt.tr1 <- prop.test(tr.table[2,2], sum(tr.table[1:2,2]), p = 0.5)
```


Now look at the CIs of the prop tests. These are the proportion of a certain level of a variable that is in group 1 (ie: the post 24/7 group). This is showing the min and max values of the proportion in group 1 (for each level of variable) that are compatible with our data. 

```{r}
ctas.pt.cis <- data.frame(row.names = colnames(wb_data[c(9:13)]), round(matrix(data = c(pt.ctas1$conf.int, pt.ctas2$conf.int, pt.ctas3$conf.int, pt.ctas4$conf.int, pt.ctas5$conf.int), nrow = 5, ncol = 2, byrow = TRUE), 3))
colnames(ctas.pt.cis) <- c("2.5%", "97.5%")
ctas.pt.cis

to.pt.cis <- data.frame(row.names = colnames(wb_data[c(14:16)]), round(matrix(data = c(pt.to1$conf.int, pt.tos2$conf.int, pt.to3$conf.int), nrow = 3, ncol = 2, byrow =TRUE), 3))
colnames(to.pt.cis) <- c("2.5%", "97.5%")
to.pt.cis

i.pt.cis <- data.frame(row.names = c("imaging0", "imaging1"), round(matrix(data = c(pt.i0$conf.int, pt.i1$conf.int), nrow = 2, ncol = 2, byrow =TRUE), 3))
colnames(i.pt.cis) <- c("2.5%", "97.5%")
i.pt.cis

a.pt.cis <- data.frame(row.names = c("adm0", "adm1"), round(matrix(data = c(pt.a0$conf.int, pt.a1$conf.int), nrow = 2, ncol = 2, byrow =TRUE), 3))
colnames(a.pt.cis) <- c("2.5%", "97.5%")
a.pt.cis

tr.pt.cis <- data.frame(row.names = c("trauma0", "trauma1"), round(matrix(data = c(pt.tr0$conf.int, pt.tr1$conf.int), nrow = 2, ncol = 2, byrow =TRUE), 3))
colnames(tr.pt.cis) <- c("2.5%", "97.5%")
tr.pt.cis

```
Only CTAS and Trauma have levels where CIs go beyond 2% fromm 0.5. That means a max 4% difference between groups at certain levels of CTAS and Trauma. This suggests there may be some sort of relationship, but not a strong one. Notice ctas1 has a CI that goes up to 0.543, this is due to small numbers of ctas1 (this is widest of all CIs).

Todseen, imaging, and adm have at most 1.6% from 0.5 and many levels have chunks of CI that cross or are very close to 0.5. 

I honnestly don't think any of these variables have an important relationship with group. If I saw these numbers in an RCT, I wouldn't bat an eyelash and would be believe that randomization worked. If we really want to force ourselves to think that there might be confounding, maybe trauma and ctas have some sort of relationship with group (ie: imbalance). 

Group is pre vs post 24/7, is there some reason to think that there is a relationship between group and any of the indepenant variables?


Now we can look at the relationship between the variables and outcome. 
```{r}
boxplot(wb_data$mdex ~ wb_data$trauma, xlab = "trauma", ylab = "mdex")
boxplot(wb_data$mdex ~ wb_data$adm, xlab = "adm", ylab = "mdex")
boxplot(wb_data$mdex ~ wb_data$todseen, xlab = "toseen", ylab = "mdex")
boxplot(wb_data$mdex ~ wb_data$ctas, xlab = "ctas", ylab = "mdex")
boxplot(wb_data$mdex ~ wb_data$imaging, xlab = "imaging", ylab = "mdex")
```

That's a bit hard to see with the outliers, so take them out:
```{r}
boxplot(wb_data$mdex ~ wb_data$trauma, xlab = "trauma", ylab = "mdex", outline = F)
boxplot(wb_data$mdex ~ wb_data$adm, xlab = "adm", ylab = "mdex", outline = F)
boxplot(wb_data$mdex ~ wb_data$todseen, xlab = "toseen", ylab = "mdex", outline = F)
boxplot(wb_data$mdex ~ wb_data$ctas, xlab = "ctas", ylab = "mdex", outline = F)
boxplot(wb_data$mdex ~ wb_data$imaging, xlab = "imaging", ylab = "mdex", outline = F)
```
They all seem to have some sort of relationship with the outcome. 


Let's do some univariate regressions, and then do multivariate with Trauma, CTAS, and Group. I think the univariate poisson regresion mdex ~ group is probably the best due to the weakness of the Trauma and CTAS relastionships with group. I'm not convinced Adm, Todseen, and Imaging should be considered and I don't see a strong relationship between them and Group. If there is some good reason for including them, then we can do that (eg: once the 24/7 was implmented, more cases that were likely to be admissions were sent to this hospital instead of another one). 
```{r}
g.uni <- glm(data = wb_data, formula = mdex ~ group, family = poisson(link = "log"))
i.uni <- glm(data = wb_data, mdex ~ imaging, family = "poisson")
tr.uni <- glm(data = wb_data, mdex ~ trauma, family = "poisson")
a.uni <- glm(data = wb_data, mdex ~ adm, family = "poisson")
c.uni <- glm(data = wb_data, mdex ~ ctas, family = "poisson")
to.uni <- glm(data = wb_data, mdex ~ todseen, family = "poisson")

g.tr.c.multi <- glm(data = wb_data, mdex ~ group + trauma + ctas, family = "poisson")
g.tr.multi <- glm(data = wb_data, mdex ~ group + trauma, family = "poisson")
g.c.multi <- glm(data = wb_data, mdex ~ group + ctas, family = "poisson")
tr.c.multi <- glm(data = wb_data, mdex ~ trauma + ctas, family = "poisson")

all.multi <- glm(data = wb_data, mdex ~ group + imaging + trauma + ctas + todseen + adm, family = "poisson")

library("stargazer")

```

```{r results= 'asis'}
stargazer(g.uni, tr.uni, c.uni, g.tr.multi, g.c.multi, tr.c.multi, g.tr.c.multi, all.multi, ci = TRUE, ci.level = 0.95, type = "html")
```
Group changes a bit when trauma is brought in and changes a bit more when CTAS is brought in. That is evidence of confounding. 

```{r}

g.adm.multi <- glm(data = wb_data, mdex ~ group + adm, family = "poisson")

g.to.multi <- glm(data = wb_data, mdex ~ group + todseen, family = "poisson")
g.i.multi <- glm(data = wb_data, mdex ~ group + imaging, family = "poisson")

```

```{r results= 'asis'}
stargazer(g.uni, a.uni, to.uni, i.uni, g.adm.multi, g.to.multi, g.i.multi,  ci = TRUE, ci.level = 0.95, type = "html")
```
Group doesn't change when todseen is brought in. Changes a bit when imaging is brought in. Group changes a when adm is brought in (almost goes o zero). That is evidence of confounding, but recall that the relationship between these variables and group is weak. Are we at risk of adjuting on a collider here? I'm not sure. Maybe these adjustments here are distorting the true relationship. Recall the boxplots that showed adm and imaging have what appear to be very strong relationships with mdex (confirmed by coefficients in these regressions). Could it be that since they are such strong determinants of mdex, the slightest bit of random noise in them drowns out/distorts the effect of group? Maybe consider simulating a data set to explore this. 

**Winbugs**
Take a look at poisson in Winbugs. 

Here is the univariate model for the data with missing value rows removed and no impuation:
model
{
    for (i in 1:165429) {		
    log(mu[i])  <- alpha + b.group*group[i]   
	mdex[i]   ~ dpois(mu[i])                     
	    }
    alpha    ~ dnorm(0.0,1.0E-4)
    b.group    ~ dnorm(0.0,1.0E-4)
 }

#inits
list(alpha=0, b.group=0)
#data
mdex[]	group[]

Here is the model for the data with missing value included and with impuation:

model
{
    for (i in 1:174829) {				#got the n from R, did nrows, there are more rows for this simple reg because there are missing mdex values
    log(mu[i])  <- alpha + b.group*group[i]  

	mdex[i]   ~ dpois(mu[i])                      # poisson dist of outcome TAT, only missing y values, so it will impute here
    }
    alpha    ~ dnorm(0.0,1.0E-4)
    b.group    ~ dnorm(0.0,1.0E-4)
  }

#inits
list(alpha=0, b.group=0)
#data
mdex[]	group[]

The results are below and compared to the R frequentist output. They are the same, as expected since the priors are uninformative and there isn't much missing data. 
```{r}

wb.results.g.uni.noImp <- read.delim("Winbugs files/pois_uni_noNA_noImp.txt")
wb.results.g.uni.Imp <- read.delim("Winbugs files/pois_uni_NA_imp.txt")

#winbug output with missing values removed and without imputation
wb.results.g.uni.noImp

#winbugs with missing values included and with imputation
wb.results.g.uni.Imp

g.uni
confint(g.uni)

```


Here is the multivariate model for the data with missing value rows removed and no impuation (x in place of * to counter markdown formatting):
model
{
    for (i in 1:165429) {				#got the n from R, did nrows, there are more rows for this simple reg because there are missing mdex values
    log(mu[i])  <- alpha + b.groupxgroup[i] + b.ctas2xctas2[i] + b.ctas3xctas3[i] + b.ctas4xctas4[i] + b.ctas5xctas5[i] + b.imagingximaging[i] + b.todseen2xtodseen2[i] +  b.todseen3xtodseen3[i] + b.traumaxtrauma[i] + b.admxadm[i]  # multiple Regression function

	mdex[i]   ~ dpois(mu[i])                      
    }
    alpha    ~ dnorm(0.0,1.0E-4)
    b.group    ~ dnorm(0.0,1.0E-4)
		b.ctas2    ~ dnorm(0.0,1.0E-4)
	b.ctas3   ~ dnorm(0.0,1.0E-4)
		b.ctas4    ~ dnorm(0.0,1.0E-4)
	b.ctas5    ~ dnorm(0.0,1.0E-4)
    b.imaging    ~ dnorm(0.0,1.0E-4)
 b.todseen2    ~ dnorm(0.0,1.0E-4)
	 b.todseen3    ~ dnorm(0.0,1.0E-4)
	b.trauma    ~ dnorm(0.0,1.0E-4)
    b.adm    ~ dnorm(0.0,1.0E-4)
 }

#inits
list(alpha=0, b.group=0, b.ctas2=0, b.ctas3=0, b.ctas4=0, b.ctas5=0, b.imaging=0, b.todseen2=0, b.todseen3=0, b.trauma=0, b.adm=0 )
#data
mdex[]	imaging[]	trauma[]	group[]	adm[]	ctas2[]	ctas3[]	ctas4[]	ctas5[]	todseen2[]	todseen3[]

Here is the multivariate model for the data with missing value rows included and using simple impuation formulas (x in place of * to counter markdown formatting):
model
{
    for (i in 1:174829) {				#got the n from R, did nrows, there are more rows for this simple reg because there are missing mdex values
    log(mu[i])  <- alpha + b.groupxgroup[i] + b.ctas2xctas2[i] + b.ctas3xctas3[i] + b.ctas4xctas4[i] + b.ctas5xctas5[i] + b.imagingximaging[i] + b.todseen2xtodseen2[i] +  b.todseen3xtodseen3[i] + b.traumaxtrauma[i] + b.admxadm[i]  # multiple Regression function

	mdex[i]   ~ dpois(mu[i])                      # poisson dist of outcome TAT, only missing y values, so it will impute here

	trauma[i] ~ dbern(p.trauma[i]) 
	logit(p.trauma[i]) <- alpha.trauma + b.trauma.group*group[i]

	todseen3[i] ~ dbern(p.todseen3[i]) 
	logit(p.todseen3[i]) <- alpha.todseen3 + b.todseen3.group*group[i]
	
	todseen2[i] ~ dbern(p.todseen2[i]) 
	logit(p.todseen2[i]) <- alpha.todseen2 + b.todseen2.group*group[i]
	    }
    alpha    ~ dnorm(0.0,1.0E-4)
    b.group    ~ dnorm(0.0,1.0E-4)
		b.ctas2    ~ dnorm(0.0,1.0E-4)
	b.ctas3   ~ dnorm(0.0,1.0E-4)
		b.ctas4    ~ dnorm(0.0,1.0E-4)
	b.ctas5    ~ dnorm(0.0,1.0E-4)
    b.imaging    ~ dnorm(0.0,1.0E-4)
 b.todseen2    ~ dnorm(0.0,1.0E-4)
	 b.todseen3    ~ dnorm(0.0,1.0E-4)
	b.trauma    ~ dnorm(0.0,1.0E-4)
    b.adm    ~ dnorm(0.0,1.0E-4)
alpha.trauma   ~ dnorm(0.0,1.0E-4)
    b.trauma.group    ~ dnorm(0.0,1.0E-4)
alpha.todseen2   ~ dnorm(0.0,1.0E-4)
    b.todseen2.group    ~ dnorm(0.0,1.0E-4)
alpha.todseen3   ~ dnorm(0.0,1.0E-4)
    b.todseen3.group    ~ dnorm(0.0,1.0E-4)
 }

#inits
list(alpha=0, b.group=0, b.ctas2=0, b.ctas3=0, b.ctas4=0, b.ctas5=0, b.imaging=0, b.todseen2=0, b.todseen3=0, b.trauma=0, b.adm=0, alpha.trauma =0, b.trauma.group = 0, alpha.todseen3 = 0, b.todseen3.group = 0, alpha.todseen2 = 0, b.todseen2.group =0)
#data
mdex[]	imaging[]	trauma[]	group[]	adm[]	ctas2[]	ctas3[]	ctas4[]	ctas5[]	todseen2[]	todseen3[]

```{r}
wb.results.all.multi.noImp <- read.delim("Winbugs files/pois_allmulti_noNA_noImp.txt")
wb.results.all.multi.Imp <- read.delim("Winbugs files/pois_allmulti_NA_Imp.txt")

#winbug output with missing values removed and without imputation
wb.results.all.multi.noImp

#winbugs with missing values included and with imputation
wb.results.all.multi.Imp

all.multi
confint(all.multi)

```
As with the univariate, the results are virtually the same for the Bayesian Winbugs with or without imputation and also virtually the same as the frequntist R. 

Looking at the "all.multi" model (ie: multivariate with all independent variables included) was done just to see what it would look like. As discussed above, I lean towards the univariate model, or at most a multivariate with trauma and ctas included. I haven't run a group + ctas + trauma model in Winbugs yet. It's at this point that I realized that I should have looked into over dispersion sooner.....There definitely is overdispersion (see below). Adjusting for it won't change the point estimates but will change the confidence intervals. 

Before talking about overdispersion, here's an inital quick stab at interpreing the results:

```{r}
exp(confint(g.uni))
```
This suggests a 1.8% to 2.0% reduction in turn around time due to the effect of group. 


**Overdispersion**
Looking at overdispersion:
```{r}
std.res <- (wb_data$mdex - as.vector(g.uni$fitted.values))/sqrt(as.vector(g.uni$fitted.values))
std.res.plot.data <- data.frame(std.res = std.res, fitted = g.uni$fitted.values, group = as.factor(wb_data$group))
ggplot(std.res.plot.data, aes(x = fitted, y = std.res, col = group)) + 
  geom_point() +
  labs(title = "Testing for overdispersion") + 
  geom_abline(intercept = 0, slope = 0) + 
  geom_hline(yintercept = c(-2, 2))
  labs(title = "Testing for overdispersion (Pearson standardized residuals)", x = "Fitted Values", y = "Standardized Residuals", col = "Group")
```
So yeah, we've got overdispersion. In fact most of the standardized residuals are outside of +/- 2 SDs.

Propotion of standarized resiuals greater than +/- 2 SDs:
```{r}

(sum(std.res > 2) + sum(std.res < -2))/length(std.res)
  
```



Do it again using quasi poisson. There is overinflation (the variance is greater than the mean, this is quite common). The quasi poisson is one way to adjust for it. This doesn't affect he Point Estimates, but it does widden the Confidence Intervals and affect inference. 
```{r}
q.g.uni <- glm(data = wb_data, formula = mdex ~ group, family = quasi(variance = "mu", link = "log"))
q.i.uni <- glm(data = wb_data, mdex ~ imaging,  family = quasi(variance = "mu", link = "log"))
q.tr.uni <- glm(data = wb_data, mdex ~ trauma,  family = quasi(variance = "mu", link = "log"))
q.a.uni <- glm(data = wb_data, mdex ~ adm, family = quasi(variance = "mu", link = "log"))
q.c.uni <- glm(data = wb_data, mdex ~ ctas,  family = quasi(variance = "mu", link = "log"))
q.to.uni <- glm(data = wb_data, mdex ~ todseen, family = quasi(variance = "mu", link = "log"))

q.g.tr.c.multi <- glm(data = wb_data, mdex ~ group + trauma + ctas,  family = quasi(variance = "mu", link = "log"))
q.g.tr.multi <- glm(data = wb_data, mdex ~ group + trauma,  family = quasi(variance = "mu", link = "log"))
q.g.c.multi <- glm(data = wb_data, mdex ~ group + ctas,  family = quasi(variance = "mu", link = "log"))
q.tr.c.multi <- glm(data = wb_data, mdex ~ trauma + ctas,  family = quasi(variance = "mu", link = "log"))

q.all.multi <- glm(data = wb_data, mdex ~ group + imaging + trauma + ctas + todseen + adm,  family = quasi(variance = "mu", link = "log"))

```

```{r results= 'asis'}
stargazer(q.g.uni, q.tr.uni, q.c.uni, q.g.tr.multi, q.g.c.multi, q.tr.c.multi, q.g.tr.c.multi, q.all.multi, ci = TRUE, ci.level = 0.95, type =  "html")
```
Notice the confidence intervals getting wider. 

```{r}
exp(confint(q.g.uni))
```
Now this adjusted quasi poisson univariate model suggests a reduction in urn around time from 0.6% to 3.1%

Use BIC to select a model. There are so many observations that there really is no risk of overfitting, so it keeps all variables in.
```{r}
library(BMA)

smaller.bic <- bic.glm.formula(data = wb_data, f = mdex ~ group + trauma + ctas, glm.family = "poisson", OR = 1000000)
summary(smaller.bic)

q.smaller.bic <- bic.glm.formula(data = wb_data, f = mdex ~ group + trauma + ctas, glm.family = quasi(variance = "mu", link = "log"), OR = 1000000)
summary(q.smaller.bic)

all.vars.bic <- bic.glm.formula(data = wb_data, f = mdex ~ group + trauma + ctas + adm + todseen + imaging, glm.family = "poisson", OR = 1000000)
summary(all.vars.bic)

```

To do: 
-simulate a data set where the noise of an independent but relatively strong determinant pushes around the detrminant of interest. 
-look at regressions with outliers cut out (over 1000 minutes) and see if there is a big difference
