---
title: "247_data_analysis_for_Sabeena"
author: "Marshall"
date: '2019-05-02'
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,          # don't show code
  warning = FALSE,       # don't show warnings
  message = FALSE,       # don't show messages (less serious warnings)
  cache = FALSE,         # set to TRUE to save results from last compilation
  fig.align = "center",   # center figures
  fig.asp = 1,          # fig.aspect ratio
  fig.width = 5       # fig width
)

```

Summary 

Model: poisson regression with a negative binomial adjustment. 

Confouding: there isn't evidence of strong relationships between the potential confounders and the intervention (group), but the effect of group isn't strong, so I don't think it would take strong confounding to seriously influence the relationship between group and turn around time (mdex)

Results: if potential confoudning is ignored and we only look at a univariate model, there is a modest decrease in turn around time due to group (0.6% to 3.1%). If we include potential confounders in various models, there is an *increase* in turn around time due to group (1.4% to 4.0%).

Next Steps in analysis: I'm going to run multivariate models in winbugs. I've also reached out to Dr Joseph to see what he thinks. It's possible that a NB poisson model is not appropriate or that I should configure my data in some other way. 

```{r}
setwd("/Users/macbook/Documents/McGill School/Sabeena_Radiology_Outcomes")

#this data has the blank rows and "all-but-id" blank rows removed. It also has extrat binary colmns for the categorical variables for use in winbugs
wb_data <- read.csv("247_data_no_NA_GOOD.csv")
wb_data_na <- read.csv("247_data_some_NA_GOOD.csv")

wb_data$X <- NULL
wb_data_na$X <- NULL

#set factors to factors
wb_data$ctas1 <- as.factor(wb_data$ctas1)
wb_data$ctas2 <- as.factor(wb_data$ctas2)
wb_data$ctas3 <- as.factor(wb_data$ctas3)
wb_data$ctas4 <- as.factor(wb_data$ctas4)
wb_data$ctas5 <- as.factor(wb_data$ctas5)
wb_data$ctas <- as.factor(wb_data$ctas)
wb_data$todseen <- as.factor(wb_data$todseen)
wb_data$todseen1 <- as.factor(wb_data$todseen1)
wb_data$todseen2 <- as.factor(wb_data$todseen2)
wb_data$todseen3 <- as.factor(wb_data$todseen3)
wb_data$group <- as.factor(wb_data$group)
wb_data$imaging <- as.factor(wb_data$imaging)
wb_data$trauma <- as.factor(wb_data$trauma)
wb_data$adm <- as.factor(wb_data$adm)

#repeat with na
wb_data_na$ctas1 <- as.factor(wb_data_na$ctas1)
wb_data_na$ctas2 <- as.factor(wb_data_na$ctas2)
wb_data_na$ctas3 <- as.factor(wb_data_na$ctas3)
wb_data_na$ctas4 <- as.factor(wb_data_na$ctas4)
wb_data_na$ctas5 <- as.factor(wb_data_na$ctas5)
wb_data_na$ctas <- as.factor(wb_data_na$ctas)
wb_data_na$todseen <- as.factor(wb_data_na$todseen)
wb_data_na$todseen1 <- as.factor(wb_data_na$todseen1)
wb_data_na$todseen2 <- as.factor(wb_data_na$todseen2)
wb_data_na$todseen3 <- as.factor(wb_data_na$todseen3)
wb_data_na$group <- as.factor(wb_data_na$group)
wb_data_na$imaging <- as.factor(wb_data_na$imaging)
wb_data_na$trauma <- as.factor(wb_data_na$trauma)
wb_data_na$adm <- as.factor(wb_data_na$adm)

library(ggplot2)

```

Checking out the distribution of turn around time (mdex). 

```{r}

ggplot(data = wb_data_na, aes(x = mdex, color = group)) + 
  geom_histogram(binwidth = 200, alpha = 0.2, position = "identity", fill = "white") +
  labs(title = "Turn Around Time Distribution by Group", color = "Group", x = "Turn Around Time (minutes)", y = "Count") +
  scale_color_discrete(name = "Group", labels = c("pre-24/7","post 24/7"))
#looks like poisson, looks like group 1 and 2 have extreme observations

#look at the 0-1000 mdex range
ggplot(data = wb_data_na, aes(x = mdex, color = group)) + 
  geom_histogram(binwidth = 50, alpha = 0.2, position = "identity", fill = "white") + xlim(0, 1000) +
  labs(title = "Turn Around Time Distribution by Group", subtitle = "TAT < 1000 mins", color = "Group", x = "Turn Around Time (minutes)", y = "Count") +
  scale_color_discrete(name = "Group", labels = c("pre-24/7","post 24/7"))

ggplot(data = wb_data_na, aes(x = mdex, color = group)) + 
  geom_histogram(binwidth = 5, alpha = 0.2, position = "identity", fill = "white") + xlim(0, 100) +
  labs(title = "Turn Around Time Distribution by Group", subtitle = "TAT < 100 mins", color = "Group", x = "Turn Around Time (minutes)", y = "Count") +
  scale_color_discrete(name = "Group", labels = c("pre-24/7","post 24/7"))


#the 95th quantil is this
#quantile(wb_data_na$mdex, 0.95, na.rm = T)
#mean(wb_data_na$mdex, na.rm = T)
#sd(wb_data_na$mdex, na.rm = T)
#mean is smaller than the sd...check for overdispersion later


```

It looks like a poisson distribution. Turn Around Time (TAT; mdex) is like survival time, it's a count of minutes that is takes. There are no negative values, it is a count of minutes, most counts are small but they can go out to infinity, not many (are there other things I need to state to justify?). It is assuming low homogeneous intensity, in that they occur at random. It is also assuming that the mean and the sd are the same, though this is seldom the case with real data sets.

Now let's take a look at the TAT (mdex) in each group.
```{r}

ggplot(data = wb_data_na, aes(x = group, y = mdex)) + geom_boxplot() +
  labs(title = "Turn Around Time by Group", x = "Group", y = "Turn Around Time (minutes)") +
  scale_x_discrete(labels = c("pre 24/7", "post 24/7"))

ggplot(data = wb_data_na, aes(x = group, y = mdex)) + geom_boxplot(outlier.shape = NA) +
  scale_y_continuous(limits = c(0, 600)) +
  labs(title = "Turn Around Time by Group", subtitle = "Outliers Removed", x = "Group", y = "Turn Around Time (minutes)") +
  scale_x_discrete(labels = c("pre 24/7", "post 24/7"))

var(wb_data$mdex)
mean(wb_data$mdex)
```
It doesn't look like a huge difference between the groups. Note that the mean and variance are different. Likely dealing with overdispersion. 


**Table 1 Descriptives and Potential Confounding**
Let's look into potential confounders. See which variables appear to have a relationship with the intervention (group) AND with the outcome (turn around time, labelled "mdex").

Take a quick look at "Table 1" stratified by group to see if there are any imbalances of variables between the groups. An imbalance between groups would suggest a relationship with the group. 
```{r}
#install.packages("table1")
library(table1)


#manipulate data set for Table 1, wont do it now, but if the table should be nicer, then we can label all the categories
table1_data_na <- wb_data_na
table1_data_na$group <- factor(table1_data_na$group, levels = c(0,1), labels = c("pre 24/7", "post 24/7"))
table1_data_na$trauma <- factor(table1_data_na$trauma, levels = c(0,1), labels = c("Non-Trauma Pt", "Trauma Pt"))
table1_data_na$todseen <- factor(table1_data_na$todseen, levels = c(1,2,3), labels = c("Morning", "Evening", "Night"))
table1_data_na$imaging <- factor(table1_data_na$imaging, levels = c(0,1), labels = c("No Imaging", "Imaging Done"))
table1_data_na$adm <- factor(table1_data_na$adm, levels = c(0,1), labels = c("Not Admitted", "Admitted"))
table1_data_na$ctas <- factor(table1_data_na$ctas, levels = c(1,2,3,4,5), labels = c("Dead/Resus", 2, 3, 4, "Almost Normal"))

table1(~ ctas + imaging + adm + todseen + trauma + mdex | group, data = table1_data_na)


```
Everything looks pretty balanced. A couple of spots that have a difference of 1.2% between the groups, but most are less than 1%.
Side note: we can see the median and mean for each group. We can also see Where the missing data is. It's about 5% of the mdex, 5% of todseen, and less than 1% of the trauma.


Can sub-stratify by trauma and ctas if we want. I do that because those might be the least balanced of all the variables (I do proportion tests further down).
```{r}
table1(~ ctas + imaging + adm + todseen + mdex | group*trauma, data = table1_data_na)

table1(~ trauma + imaging + adm + todseen + mdex | group*ctas, data = table1_data_na)
```
Still looking very balanced. Note that this is a quick look and it tells us that none of the potential confounders has a super strong relationship with group. We can also see that the TAT (mdex) aren't hugely different between the groups either. We will come back to this later. 

When stratified by tauma: CTAS maybe has a couple of spots that are between 1% and 1.5% different. Imaging and Adm have spots with 1.2% difference.  

When stratified by ctas: there are some spots where it's 3% different. But now we're really slicing and dicing. 


If we REALLY want to look hard, we can look at each level of each variable and see the propotion that is in each group. Perfect balance (and no relationship with group) would be 0.5, so we can do a bunch of tests of propotion vs the null of 0.5. I'm not sure this adds a lot of value since the n is so large, the CIs are very tight and some of them end up not covering the null even though the proportion is something like 0.51.
```{r}
#check columns proportions, not just overall
c.table <- table(table1_data_na$group, table1_data_na$ctas)
round(prop.table(c.table, 2), 3)
pt.ctas1 <- prop.test(c.table[2,1], sum(c.table[1:2,1]), p = 0.5)
pt.ctas2 <-  prop.test(c.table[2,2], sum(c.table[1:2,2]), p = 0.5)
pt.ctas3 <-  prop.test(c.table[2,3], sum(c.table[1:2,3]), p = 0.5)
pt.ctas4 <-  prop.test(c.table[2,4], sum(c.table[1:2,4]), p = 0.5)
pt.ctas5 <-  prop.test(c.table[2,5], sum(c.table[1:2,5]), p = 0.5)


to.table <- table(table1_data_na$group, table1_data_na$todseen)
round(prop.table(to.table, 2), 3)
pt.to1 <- prop.test(to.table[2,1], sum(to.table[1:2,1]), p = 0.5)
pt.tos2 <-  prop.test(to.table[2,2], sum(to.table[1:2,2]), p = 0.5)
pt.to3 <-  prop.test(to.table[2,3], sum(to.table[1:2,3]), p = 0.5)


i.table <- table(table1_data_na$group, table1_data_na$imaging)
round(prop.table(i.table, 2), 3)
pt.i0 <- prop.test(i.table[2,1], sum(i.table[1:2,1]), p = 0.5)
pt.i1 <-  prop.test(i.table[2,2], sum(i.table[1:2,2]), p = 0.5)

a.table <- table(table1_data_na$group, table1_data_na$adm)
round(prop.table(a.table, 2), 3)
pt.a0 <- prop.test(a.table[2,1], sum(a.table[1:2,1]), p = 0.5)
pt.a1 <- prop.test(a.table[2,2], sum(a.table[1:2,2]), p = 0.5)

tr.table <- table(table1_data_na$group, table1_data_na$trauma)
round(prop.table(tr.table, 2), 3)
pt.tr0 <- prop.test(tr.table[2,1], sum(tr.table[1:2,1]), p = 0.5)
pt.tr1 <- prop.test(tr.table[2,2], sum(tr.table[1:2,2]), p = 0.5)
```


Now look at the CIs of the prop tests. These are the proportion of a certain level of a variable that is in group 1 (ie: the post 24/7 group). This is showing the min and max values of the proportion in group 1 (for each level of variable) that are compatible with our data. 

```{r}
ctas.pt.cis <- data.frame(row.names = colnames(wb_data[c(9:13)]), round(matrix(data = c(pt.ctas1$conf.int, pt.ctas2$conf.int, pt.ctas3$conf.int, pt.ctas4$conf.int, pt.ctas5$conf.int), nrow = 5, ncol = 2, byrow = TRUE), 3))
colnames(ctas.pt.cis) <- c("2.5%", "97.5%")
ctas.pt.cis

to.pt.cis <- data.frame(row.names = colnames(wb_data[c(14:16)]), round(matrix(data = c(pt.to1$conf.int, pt.tos2$conf.int, pt.to3$conf.int), nrow = 3, ncol = 2, byrow =TRUE), 3))
colnames(to.pt.cis) <- c("2.5%", "97.5%")
to.pt.cis

i.pt.cis <- data.frame(row.names = c("imaging0", "imaging1"), round(matrix(data = c(pt.i0$conf.int, pt.i1$conf.int), nrow = 2, ncol = 2, byrow =TRUE), 3))
colnames(i.pt.cis) <- c("2.5%", "97.5%")
i.pt.cis

a.pt.cis <- data.frame(row.names = c("adm0", "adm1"), round(matrix(data = c(pt.a0$conf.int, pt.a1$conf.int), nrow = 2, ncol = 2, byrow =TRUE), 3))
colnames(a.pt.cis) <- c("2.5%", "97.5%")
a.pt.cis

tr.pt.cis <- data.frame(row.names = c("trauma0", "trauma1"), round(matrix(data = c(pt.tr0$conf.int, pt.tr1$conf.int), nrow = 2, ncol = 2, byrow =TRUE), 3))
colnames(tr.pt.cis) <- c("2.5%", "97.5%")
tr.pt.cis


```
Only CTAS and Trauma have levels where CIs go beyond 2% fromm 0.5. That means a max 4% difference between groups at certain levels of CTAS and Trauma. This suggests there may be some sort of relationship, but not a strong one. Notice ctas1 has a CI that goes up to 0.543, this is due to small numbers of ctas1 (this is widest of all CIs).

Todseen, imaging, and adm have at most 1.6% from 0.5 and many levels have chunks of CI that cross or are very close to 0.5. 

I honnestly don't think any of these variables have an important relationship with group. If I saw these numbers in an RCT, I wouldn't bat an eyelash and would be believe that randomization worked. If we really want to force ourselves to think that there might be confounding, maybe trauma and ctas have some sort of relationship with group (ie: imbalance). 

Those were just inspecting the distribution of variables and prop tests. Could also look at a logistic regression onto group to see if there are effects. 
```{r}

group.logit <- glm(data = wb_data, group ~ ctas + adm + imaging + todseen + trauma, family = "binomial")

g.logit.all.ci <- exp(confint(group.logit))
g.logit.c.ci <- exp(confint(glm(data = wb_data, group ~ ctas, family = "binomial")))
g.logit.tr.ci <- exp(confint(glm(data = wb_data, group ~ trauma, family = "binomial")))
g.logit.a.ci <- exp(confint(glm(data = wb_data, group ~ adm, family = "binomial")))
g.logit.i.ci <- exp(confint(glm(data = wb_data, group ~ imaging, family = "binomial")))
g.logit.to.ci <- exp(confint(glm(data = wb_data, group ~ todseen, family = "binomial")))

g.logit.all.ci
g.logit.c.ci 
g.logit.tr.ci
g.logit.a.ci 
g.logit.i.ci 
g.logit.to.ci

library(BMA)

bic.glm.formula(data = wb_data, group ~ adm + trauma + ctas + imaging + todseen, glm.family = "binomial")

```
Regressing each variable onto group makes it look like adm, trauma, and ctas have relationships with group. Imaging barely does and todseen doesn't seem to. Again, no STRONG relationships between any of the potential confounders and group, however adm, trauma, and ctas seem to be the "strongest"" of all of there "super weak" relationships. Could also make a case for imaging. 

Group is pre vs post 24/7, is there some reason to think that there is a relationship between group and any of the indepenant variables?

Now we can look at the relationship between the variables and outcome. 
```{r}
boxplot(wb_data$mdex ~ wb_data$trauma, xlab = "trauma", ylab = "mdex")
boxplot(wb_data$mdex ~ wb_data$adm, xlab = "adm", ylab = "mdex")
boxplot(wb_data$mdex ~ wb_data$todseen, xlab = "toseen", ylab = "mdex")
boxplot(wb_data$mdex ~ wb_data$ctas, xlab = "ctas", ylab = "mdex")
boxplot(wb_data$mdex ~ wb_data$imaging, xlab = "imaging", ylab = "mdex")
```

That's a bit hard to see with the outliers, so take them out:
```{r}
boxplot(wb_data$mdex ~ wb_data$trauma, xlab = "trauma", ylab = "mdex", outline = F)
boxplot(wb_data$mdex ~ wb_data$adm, xlab = "adm", ylab = "mdex", outline = F)
boxplot(wb_data$mdex ~ wb_data$todseen, xlab = "toseen", ylab = "mdex", outline = F)
boxplot(wb_data$mdex ~ wb_data$ctas, xlab = "ctas", ylab = "mdex", outline = F)
boxplot(wb_data$mdex ~ wb_data$imaging, xlab = "imaging", ylab = "mdex", outline = F)
```
They all seem to have some sort of relationship with the outcome. Adm, CTAS, and imaging have the strongest relationships. That is important to keep in mind. Later, we will see that group has a very weak relationship with TAT (mdex), so does that mean we should be hyper-vigilant to even the weakest confounders? If there is evidence that adm, ctas, and imaging have weak relationships with group but strong relationships with the TAT (mdex), then maybe we should be concerned that even that weak confounding could distort the relationship between group and TAT (mdex) due to that relationship being so weak and vulnerable to confounding. 

Let's do some univariate regressions, and then do multivariate with Trauma, CTAS, Adm, Imaging, and Group. I think the univariate poisson regresion mdex ~ group is probably the best due to the weakness of the confounders' relationships with group. That being said, it might be that group's relationship with TAT (mdex) is so weak that even mild confounding can distort it.

**Poisson Regressions**
I did these before exploring over dispersion. I'm not spending too much time looking at them. Just a quick uni vs some multi. It does help show potential confounding, though I didn't include all potential confounders in table. 
```{r}
g.uni <- glm(data = wb_data, formula = mdex ~ group, family = poisson(link = "log"))
i.uni <- glm(data = wb_data, mdex ~ imaging, family = "poisson")
tr.uni <- glm(data = wb_data, mdex ~ trauma, family = "poisson")
a.uni <- glm(data = wb_data, mdex ~ adm, family = "poisson")
c.uni <- glm(data = wb_data, mdex ~ ctas, family = "poisson")
to.uni <- glm(data = wb_data, mdex ~ todseen, family = "poisson")

g.tr.c.multi <- glm(data = wb_data, mdex ~ group + trauma + ctas, family = "poisson")
g.tr.multi <- glm(data = wb_data, mdex ~ group + trauma, family = "poisson")
g.c.multi <- glm(data = wb_data, mdex ~ group + ctas, family = "poisson")
tr.c.multi <- glm(data = wb_data, mdex ~ trauma + ctas, family = "poisson")

all.multi <- glm(data = wb_data, mdex ~ group + imaging + trauma + ctas + todseen + adm, family = "poisson")

library("stargazer")
```

```{r results= 'asis'}
stargazer(g.uni, tr.uni, c.uni, g.tr.multi, g.c.multi, tr.c.multi, g.tr.c.multi, all.multi, ci = TRUE, ci.level = 0.95, type = "html")
```

Group changes a bit when trauma is brought in and changes a bit more when CTAS is brought in. That is evidence of confounding. 

Look at the other potential confounders (I split them into 2 tables to make it easier to digest).

```{r}

g.a.multi <- glm(data = wb_data, mdex ~ group + adm, family = "poisson")

g.to.multi <- glm(data = wb_data, mdex ~ group + todseen, family = "poisson")
g.i.multi <- glm(data = wb_data, mdex ~ group + imaging, family = "poisson")
#stargazer(g.uni, a.uni, to.uni, i.uni, g.a.multi, g.to.multi, g.i.multi,  ci = TRUE, ci.level = 0.95, type = "text")

```

```{r results= 'asis'}
stargazer(g.uni, a.uni, to.uni, i.uni, g.a.multi, g.to.multi, g.i.multi,  ci = TRUE, ci.level = 0.95, type = "html")
```
Group doesn't change when todseen is brought in. Changes a bit when imaging is brought in. Group changes a lot when adm is brought in (almost goes to zero). That is evidence of confounding, but recall that the relationship between these variables and group is weak. Recall the boxplots that showed adm and imaging have what appear to be very strong relationships with mdex (confirmed by coefficients in these regressions). Could it be that since they are such strong determinants of mdex, even the slightest relationship with group makes them a confounder of the relationship between group and mdex? 

Summary: evidence of confounding from adm and ctas. Maybe from imaging and trauma. Not from todseen.

**Winbugs**
Take a look at poisson in Winbugs.

Here is the univariate model for the data with missing value rows removed and no impuation:

```
model
{
    for (i in 1:165429) {		
    log(mu[i])  <- alpha + b.group*group[i]   
	mdex[i]   ~ dpois(mu[i])                     
	    }
    alpha    ~ dnorm(0.0,1.0E-4)
    b.group    ~ dnorm(0.0,1.0E-4)
 }

#inits
list(alpha=0, b.group=0)
#data
mdex[]	group[]
```

Here is the model for the data with missing value included and with impuation:
```
model
{
    for (i in 1:174829) {				#got the n from R, did nrows, there are more rows for this simple reg because there are missing mdex values
    log(mu[i])  <- alpha + b.group*group[i]  

	mdex[i]   ~ dpois(mu[i])                      # poisson dist of outcome TAT, only missing y values, so it will impute here
    }
    alpha    ~ dnorm(0.0,1.0E-4)
    b.group    ~ dnorm(0.0,1.0E-4)
  }

#inits
list(alpha=0, b.group=0)
#data
mdex[]	group[]
```

The results are below and compared to the R frequentist output. They are the same, as expected since the priors are uninformative and there isn't much missing data. 
```{r}

wb.results.g.uni.noImp <- read.delim("Winbugs files/pois_uni_noNA_noImp.txt")
wb.results.g.uni.Imp <- read.delim("Winbugs files/pois_uni_NA_imp.txt")

#winbug output with missing values removed and without imputation
wb.results.g.uni.noImp

#winbugs with missing values included and with imputation
wb.results.g.uni.Imp

g.uni
confint(g.uni)

```


Here is the multivariate model with all 5 covariates included. This is using data with missing value rows removed and no impuation (x in place of * to counter markdown formatting):
```
model
{
    for (i in 1:165429) {				#got the n from R, did nrows, there are more rows for this simple reg because there are missing mdex values
    log(mu[i])  <- alpha + b.groupxgroup[i] + b.ctas2xctas2[i] + b.ctas3xctas3[i] + b.ctas4xctas4[i] + b.ctas5xctas5[i] + b.imagingximaging[i] + b.todseen2xtodseen2[i] +  b.todseen3xtodseen3[i] + b.traumaxtrauma[i] + b.admxadm[i]  # multiple Regression function

	mdex[i]   ~ dpois(mu[i])                      
    }
    alpha    ~ dnorm(0.0,1.0E-4)
    b.group    ~ dnorm(0.0,1.0E-4)
		b.ctas2    ~ dnorm(0.0,1.0E-4)
	b.ctas3   ~ dnorm(0.0,1.0E-4)
		b.ctas4    ~ dnorm(0.0,1.0E-4)
	b.ctas5    ~ dnorm(0.0,1.0E-4)
    b.imaging    ~ dnorm(0.0,1.0E-4)
 b.todseen2    ~ dnorm(0.0,1.0E-4)
	 b.todseen3    ~ dnorm(0.0,1.0E-4)
	b.trauma    ~ dnorm(0.0,1.0E-4)
    b.adm    ~ dnorm(0.0,1.0E-4)
 }

#inits
list(alpha=0, b.group=0, b.ctas2=0, b.ctas3=0, b.ctas4=0, b.ctas5=0, b.imaging=0, b.todseen2=0, b.todseen3=0, b.trauma=0, b.adm=0 )
#data
mdex[]	imaging[]	trauma[]	group[]	adm[]	ctas2[]	ctas3[]	ctas4[]	ctas5[]	todseen2[]	todseen3[]
```

Here is the multivariate model with all 5 covariates included. This is with missing value rows included and using simple impuation formulas (x in place of * to counter markdown formatting):
```
model
{
    for (i in 1:174829) {				#got the n from R, did nrows, there are more rows for this simple reg because there are missing mdex values
    log(mu[i])  <- alpha + b.groupxgroup[i] + b.ctas2xctas2[i] + b.ctas3xctas3[i] + b.ctas4xctas4[i] + b.ctas5xctas5[i] + b.imagingximaging[i] + b.todseen2xtodseen2[i] +  b.todseen3xtodseen3[i] + b.traumaxtrauma[i] + b.admxadm[i]  # multiple Regression function

	mdex[i]   ~ dpois(mu[i])                      # poisson dist of outcome TAT, only missing y values, so it will impute here

	trauma[i] ~ dbern(p.trauma[i]) 
	logit(p.trauma[i]) <- alpha.trauma + b.trauma.group*group[i]

	todseen3[i] ~ dbern(p.todseen3[i]) 
	logit(p.todseen3[i]) <- alpha.todseen3 + b.todseen3.group*group[i]
	
	todseen2[i] ~ dbern(p.todseen2[i]) 
	logit(p.todseen2[i]) <- alpha.todseen2 + b.todseen2.group*group[i]
	    }
    alpha    ~ dnorm(0.0,1.0E-4)
    b.group    ~ dnorm(0.0,1.0E-4)
		b.ctas2    ~ dnorm(0.0,1.0E-4)
	b.ctas3   ~ dnorm(0.0,1.0E-4)
		b.ctas4    ~ dnorm(0.0,1.0E-4)
	b.ctas5    ~ dnorm(0.0,1.0E-4)
    b.imaging    ~ dnorm(0.0,1.0E-4)
 b.todseen2    ~ dnorm(0.0,1.0E-4)
	 b.todseen3    ~ dnorm(0.0,1.0E-4)
	b.trauma    ~ dnorm(0.0,1.0E-4)
    b.adm    ~ dnorm(0.0,1.0E-4)
alpha.trauma   ~ dnorm(0.0,1.0E-4)
    b.trauma.group    ~ dnorm(0.0,1.0E-4)
alpha.todseen2   ~ dnorm(0.0,1.0E-4)
    b.todseen2.group    ~ dnorm(0.0,1.0E-4)
alpha.todseen3   ~ dnorm(0.0,1.0E-4)
    b.todseen3.group    ~ dnorm(0.0,1.0E-4)
 }

#inits
list(alpha=0, b.group=0, b.ctas2=0, b.ctas3=0, b.ctas4=0, b.ctas5=0, b.imaging=0, b.todseen2=0, b.todseen3=0, b.trauma=0, b.adm=0, alpha.trauma =0, b.trauma.group = 0, alpha.todseen3 = 0, b.todseen3.group = 0, alpha.todseen2 = 0, b.todseen2.group =0)
#data
mdex[]	imaging[]	trauma[]	group[]	adm[]	ctas2[]	ctas3[]	ctas4[]	ctas5[]	todseen2[]	todseen3[]
```

```{r}
wb.results.all.multi.noImp <- read.delim("Winbugs files/pois_allmulti_noNA_noImp.txt")
wb.results.all.multi.Imp <- read.delim("Winbugs files/pois_allmulti_NA_Imp.txt")

#winbug output with missing values removed and without imputation
wb.results.all.multi.noImp

#winbugs with missing values included and with imputation
wb.results.all.multi.Imp

all.multi
confint(all.multi)

```
As with the univariate, the results are virtually the same for the Bayesian Winbugs with or without imputation and also virtually the same as the frequntist R. 

Looking at the "all.multi" model (ie: multivariate with all independent variables included) was done just to see what it would look like. As discussed above, I lean towards the univariate model, or a multivariate with only adm and ctas included. I haven't run a group + ctas + adm model in Winbugs yet. Note about model selection, in the words of Dr Joseph: "the aim of model selection is to avoid selecting a particular model". So I guess I will look at several models and try to draw a conclusion on the effect of group. 

Before talking about overdispersion, here's an inital quick stab at interpreing the results:

```{r}
exp(confint(g.uni))
```
This suggests a 1.8% to 2.0% reduction in turn around time due to the effect of group. This is a univariate model with plain old poisson without imputation, but as seen above imputation in winbugs didn't change the results. Also, note that unadjusted poisson is probably not appropriate. 

```{r}
exp(confint(all.multi))
```
0.4% too 0.5% reduction. This is a multivariate model with all 5 covariates thrown in. Plain poisson without imputation. 

**Over dispersion**
....finally.
The mean probably isn't the same and the sd, so let's look at overdispersion:
```{r}
std.res <- (wb_data$mdex - as.vector(g.uni$fitted.values))/sqrt(as.vector(g.uni$fitted.values))
std.res.plot.data <- data.frame(std.res = std.res, fitted = g.uni$fitted.values, group = as.factor(wb_data$group))
ggplot(std.res.plot.data, aes(x = fitted, y = std.res, col = group)) + 
  geom_point() +
  labs(title = "Testing for overdispersion") + 
  geom_abline(intercept = 0, slope = 0) + 
  geom_hline(yintercept = c(-2, 2))
  labs(title = "Testing for overdispersion (Pearson standardized residuals)", x = "Fitted Values", y = "Standardized Residuals", col = "Group")
```
So yeah, we've got overdispersion. In fact most of the standardized residuals are outside of +/- 2 SDs.

Propotion of standarized resiuals greater than +/- 2 SDs:
```{r}

(sum(std.res > 2) + sum(std.res < -2))/length(std.res)
  
```
We will have to do some sort of adjustment to accound for the over dispersion (more on that later).



Do it again using quasi poisson. There is overdispersion (the variance is greater than the mean, this is quite common). The quasi poisson is one way to adjust for it. This doesn't affect he Point Estimates, but it does widden the Confidence Intervals and affect inference. 
```{r}
q.g.uni <- glm(data = wb_data, formula = mdex ~ group, family = quasi(variance = "mu", link = "log"))
q.i.uni <- glm(data = wb_data, mdex ~ imaging,  family = quasi(variance = "mu", link = "log"))
q.tr.uni <- glm(data = wb_data, mdex ~ trauma,  family = quasi(variance = "mu", link = "log"))
q.a.uni <- glm(data = wb_data, mdex ~ adm, family = quasi(variance = "mu", link = "log"))
q.c.uni <- glm(data = wb_data, mdex ~ ctas,  family = quasi(variance = "mu", link = "log"))
q.to.uni <- glm(data = wb_data, mdex ~ todseen, family = quasi(variance = "mu", link = "log"))

q.g.a.c.multi <- glm(data = wb_data, mdex ~ group + adm + ctas,  family = quasi(variance = "mu", link = "log"))
q.g.a.multi <- glm(data = wb_data, mdex ~ group + adm,  family = quasi(variance = "mu", link = "log"))
q.g.c.multi <- glm(data = wb_data, mdex ~ group + ctas,  family = quasi(variance = "mu", link = "log"))
q.a.c.multi <- glm(data = wb_data, mdex ~ adm + ctas,  family = quasi(variance = "mu", link = "log"))

q.all.multi <- glm(data = wb_data, mdex ~ group + imaging + trauma + ctas + todseen + adm,  family = quasi(variance = "mu", link = "log"))

#this stargazer is for looking at in R, hashtag it out for knitting
#stargazer(q.g.uni, q.a.uni, q.c.uni, q.g.a.multi, q.g.c.multi, q.a.c.multi, q.g.a.c.multi, q.all.multi, ci = TRUE, ci.level = 0.95, type =  "text")
```

```{r results= 'asis'}
stargazer(q.g.uni, q.tr.uni, q.c.uni, q.g.a.multi, q.g.c.multi, q.a.c.multi, q.g.a.c.multi, q.all.multi, ci = TRUE, ci.level = 0.95, type =  "html")
```
Notice the confidence intervals getting wider. 


Another method to adjust for overinflation is negative binomial.
```{r}
#check  negative binomial to compare to quasi pois
library(MASS)

nb.g.uni <- glm.nb(data = wb_data, formula = mdex ~ group)
nb.i.uni <- glm.nb(data = wb_data, formula = mdex ~ imaging)
nb.tr.uni <- glm.nb(data = wb_data, formula = mdex ~ trauma)
nb.a.uni <- glm.nb(data = wb_data, formula = mdex ~ adm)
nb.c.uni <- glm.nb(data = wb_data, formula = mdex ~ ctas)
nb.to.uni <- glm.nb(data = wb_data, formula = mdex ~ todseen)

nb.g.a.c.multi <- glm.nb(data = wb_data, mdex ~ group + adm + ctas)
nb.g.tr.multi <- glm.nb(data = wb_data, mdex ~ group + trauma)
nb.g.c.multi <- glm.nb(data = wb_data, mdex ~ group + ctas)
nb.a.c.multi <- glm.nb(data = wb_data, mdex ~ adm + ctas)
nb.g.a.multi <- glm.nb(data = wb_data, mdex ~ group + adm)

nb.g.tr.c.a.multi <- glm.nb(data = wb_data, mdex ~ group + trauma + ctas + adm)

nb.all.multi <- glm.nb(data = wb_data, mdex ~ group + imaging + trauma + ctas + todseen + adm)

#this stargazer is for looking at in R, hashtag it out for knitting. Comparing all the q-p to nb
#stargazer(q.g.uni, nb.g.uni, ci = TRUE, ci.level = 0.95, type =  "text")
#stargazer(q.i.uni, nb.i.uni, ci = TRUE, ci.level = 0.95, type =  "text")
#stargazer(q.tr.uni, nb.tr.uni, ci = TRUE, ci.level = 0.95, type =  "text")
#stargazer(q.a.uni, nb.a.uni, ci = TRUE, ci.level = 0.95, type =  "text")
#stargazer(q.c.uni, nb.c.uni, ci = TRUE, ci.level = 0.95, type =  "text")
#stargazer(q.to.uni, nb.to.uni, ci = TRUE, ci.level = 0.95, type =  "text")

#that's all nice and dandy, really, the only ones I might look at are group, group+traum+ctas, all
#stargazer(nb.g.uni, q.g.tr.c.multi, nb.g.tr.c.multi, q.all.multi, nb.all.multi, ci = TRUE, ci.level = 0.95, type =  "text")

#looking for adm confouding, loooks like it's there
#stargazer(nb.g.uni, nb.a.uni, nb.g.a.multi, nb.all.multi, ci = TRUE, ci.level = 0.95, type =  "text")

#look at three most reasonable models
#stargazer(nb.g.uni, nb.g.tr.c.multi, nb.g.tr.c.a.multi, nb.all.multi, ci = TRUE, ci.level = 0.95, type =  "text")
#depending on which covariates we chose to include in our model, the effect of group could be a slight decrease in TAT or a slight increase in TAT. 

```
That entered all of them in. Let's see how they compare to the quasi - poisson:

```{r results= 'asis'}
stargazer(q.g.uni, nb.g.uni,q.i.uni, nb.i.uni, q.tr.uni, nb.tr.uni, q.a.uni, nb.a.uni, q.c.uni, nb.c.uni, q.to.uni, nb.to.uni, ci = TRUE, ci.level = 0.95, type =  "html")
```
All the PE for the univariates stay the same, but the CIs get smaller under NB. 


Now let's compare how the multivariate quasi-poisson and multivariate NB describe the effect of group.
```{r results= 'asis'}
#that's all nice and dandy, really, the only ones I might look at are group, group+adm+ctas, all
stargazer(nb.g.uni, q.g.a.c.multi, nb.g.a.c.multi, q.all.multi, nb.all.multi, ci = TRUE, ci.level = 0.95, type =  "html")

#looking for adm confouding, loooks like it's there
stargazer(nb.g.uni, nb.a.uni, nb.g.a.multi, nb.all.multi, ci = TRUE, ci.level = 0.95, type =  "html")

#look at three most reasonable models
stargazer(nb.g.uni, nb.g.a.c.multi, nb.g.tr.c.a.multi, nb.all.multi, ci = TRUE, ci.level = 0.95, type =  "html")
#depending on which covariates we chose to include in our model, the effect of group could be a slight decrease in TAT or a slight increase in TAT. 
```
The NB seems to move the group coefficient to positive. Sort of no matter how we look at it. 


Which one to choose? I read a paper that said the NB gives more weight to the lower values of mdex when it fits the regression, so it is better for predicting the lower end, whereas q-p is the opposite. There is a value of "count" where the thetas of both methods give the same variance. Look for the mean count value where the variance of the NB and the q-p are the same
```{r}
sum.q.g <- summary(q.g.uni)
theta.q <- sum.q.g$dispersion

sum.nb.g <- summary(nb.g.uni)
sum.nb.g
theta.nb <- nb.g.uni$theta

#mu * theta.q = mu * (1 + theta.nb * mu)
eq.var.mu <- (theta.q - 1) / theta.nb
#so the count at which the variances for nb and qp are equal is 534 minutes. Let's see what quantile that is
quantile(wb_data_na$mdex, 0.88, na.rm = T)
#approx 88% of our data points are below 534 minutes. We want a model that prioritizes that fit. So we want NB. 

```
The "break even" point for adjusted variance and thus weighting is 534. Most of our interesting data is below there (that is more the "routine" operations as I understand it). That suggests that we should use NB. 


```{r}
uni.cis <- exp(confint(g.uni))

q.uni.cis <- exp(confint(q.g.uni))

nb.uni.cis <- exp(confint(nb.g.uni))
nb.uni.cis

multi.cis <- exp(confint(all.multi))

q.multi.cis <- exp(confint(q.all.multi))

nb.multi.cis <- exp(confint(nb.all.multi))
nb.multi.cis

nb.g.a.c.multi.cis <- exp(confint(nb.g.a.c.multi))
nb.g.a.c.multi.cis

```
The NB univariate model suggests a reduction in turn around time from 0.6% to 3.1%.
The NB multivariate model with all covariates suggests an INCREASE in turn around time from 2.4% to 4.0%. That is the multi model with everything in. 
The NB multivariate model with ctas and adm suggests an INCREASE in turn around time from 1.4% to 3.2%. That is the multivariate model that includes confoudners that I think have the stringest evidence, though it is still weak confounding. 

```{r}
#wb_data_play

#play.uni <- glm.nb(data = wb_data_play, formula = mdex ~ group)
#exp(confint(play.uni))
#summary(play.uni)

#Hot damn it works!

#now try imputation?

wb.results.NB.uni.noImp <- read.delim("Winbugs files/NBpois_uni_noNA_noImp.txt")
wb.results.NB.uni.noImp


wb.results.NB.uni.Imp <- read.delim("Winbugs files/NBpois_uni_NA_Imp.txt")
wb.results.NB.uni.Imp
nb.g.uni
confint(nb.g.uni)
```
I built and ran a winbugs model without and with imputation and they give a very similar results (including thetas, called r in the winbugs files) to the R frequentist NB analysis. Notet that the CI is a little wider on the impuation, as we would expect....and hope for! The next step would be to run this on a multivarite NB model. I'm guessing/hoping it will give the same results.

FYI, the winbugs model with missing values and imp is (the no missing values and no Imp is virtually the same):
```
model
{
    for (i in 1:174829) {				
	mdex[i] ~ dnegbin( p[i], r)
	p[i] <- r / ( r + lambda[i] )
    log(lambda[i])  <- alpha + b.group*group[i] 
    }
    alpha    ~ dnorm(0.0,1.0E-4)
    b.group    ~ dnorm(0.0,1.0E-4)
	r ~ dgamma(0.001, 0.001)

 }

#inits
list(alpha=0, b.group=0, r = 1)

mdex[]	group[]
```


Use BIC to select a model. Not sure if this is the most useful, it wants to kick out group, that's because group is a very poor predictor of mdex, so for a predictive model, it's not useful to have group in there. I'm not so much interested in model selection for prediction as I am in determining the effect of group. 
```{r}
library(BMA)

smaller.bic <- bic.glm.formula(data = wb_data, f = mdex ~ group + trauma + ctas, glm.family = "poisson", OR = 1000000)
summary(smaller.bic)

q.smaller.bic <- bic.glm.formula(data = wb_data, f = mdex ~ group + trauma + ctas + adm, glm.family = quasi(variance = "mu", link = "log"), OR = 1000000)
summary(q.smaller.bic)

all.vars.bic <- bic.glm.formula(data = wb_data, f = mdex ~ group + trauma + ctas + adm + todseen + imaging, glm.family = "poisson", OR = 1000000)
summary(all.vars.bic)

```

To do: 
-run winbugs NB multivariate
-simulate a data set where the noise of an independent but relatively strong determinant pushes around the detrminant of interest. 
-look at regressions with outliers cut out (over 1000 minutes) and see if there is a big difference
